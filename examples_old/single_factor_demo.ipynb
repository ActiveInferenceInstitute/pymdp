{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Inference: Simple Generative Model\n",
    "This notebook simulates an active inference agent behaving in a random environment described by a single hidden state variable and a single observation modality. The agent uses variational inference to infer the most likely hidden states, and optimizes its policies with respect to those that minimize the expected free energy of their attendant observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import basic paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "path = Path(os.getcwd())\n",
    "module_path = str(path.parent) + '/'\n",
    "sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import `inferactively` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import special\n",
    "\n",
    "from inferactively.distributions import Categorical, Dirichlet\n",
    "from inferactively import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define an auxiliary function for creating the transition likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_B(Ns, Nf, controllableActionIdx):\n",
    "    \"\"\"\n",
    "    Generate controlled transitions for each hidden state factor, that correspond to actions.\n",
    "    \"\"\"\n",
    "\n",
    "    B = np.empty((Nf),dtype=object)\n",
    "    for si, ndim_si in enumerate(Ns):\n",
    "        B[si] = np.eye(ndim_si)\n",
    "\n",
    "    # controllable hidden state factors - transition to the k-th location\n",
    "\n",
    "    for pi in controllableActionIdx:\n",
    "        B[pi] = np.tile(B[pi].reshape(Ns[pi],Ns[pi],1),(1,1,Ns[pi])).transpose((1,2,0))\n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The generative process\n",
    "Here, we setup the mechanics of the environment, or the 'generative process.' To make this analogous to the generative _model_ learned by the agent, we describe these mechanics using likelihood distribution $P(o_t|s_t)$, denoted `A_GP`, and a transition distribution $P(s_t|s_{t-1},a_{t-1})$, denoted `B_GP`. The generative process will be used to generate observations `obs` via the likelihood $P(o_t|s_t)$ and is changed by actions via the likelihood $P(s_t|s_{t-1},a_{t-1})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up state-space and outcome-space dimensionalities of the generative process\n",
    "No = [4]     # dimensionality of the different outcome modalities\n",
    "Ng = len(No) # total number of outcome modalities\n",
    "\n",
    "Ns = [3]     # dimensionality of the hidden state factors\n",
    "Nf = len(Ns) # toatl number of hidden state factors\n",
    "\n",
    "# Create the likelihoods and priors relevant to the generative model\n",
    "\n",
    "A_GP = Categorical(values = np.random.rand(*(No+Ns))) # observation likelihood\n",
    "A_GP.normalize()\n",
    "\n",
    "B_GP = Categorical(values = create_B(Ns, Nf, [0])[0] ) # transition likelihood\n",
    "\n",
    "initState_idx = np.random.randint(*Ns) # sample a random initial state\n",
    "initState = np.eye(*Ns)[initState_idx] # one-hot encode it\n",
    "\n",
    "T = 100 # number of timesteps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The generative model\n",
    "Here, we setup the belief structure of the active inference agent, or the 'generative model.' For this simple case, we make the generative model identical to the generative process. Namely, the agent's beliefs about the observation and likelihood distributions (respectively, the _observation model_ and _transition model_ ) are identical to the true parameters describing the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generative model likelihoods\n",
    "A_GM = Categorical(values = A_GP.values) # in this case, the generative model and the generative process are identical\n",
    "B_GM = Categorical(values = B_GP.values) # in this case, the generative model and the generative process are identical\n",
    "\n",
    "# Prior Dirichlet parameters (these parameterize the generative model likelihoods)\n",
    "pA = Dirichlet(values = A_GM.values * 1e20) # fix prior beliefs about observation likelihood to be really high (and thus impervious to learning)\n",
    "pB = Dirichlet(values = B_GP.values * 1e20) # fix prior beliefs about transition likelihood to be really high (and thus impervious to learning)\n",
    "\n",
    "# create some arbitrary preference about observations\n",
    "C = np.zeros(*No)\n",
    "C[0] = -2 # prefers not to observe the outcome with index == 0\n",
    "C[-1] = 2 # prefers to observe the outcome with highest index\n",
    "\n",
    "# initialize a flat prior \n",
    "prior = Categorical(values = np.ones(Ns[0])/Ns[0])\n",
    "\n",
    "# policy related parameters\n",
    "policy_horizon = 1\n",
    "cntrl_fac_idx = [0] # which indices of the hidden states are controllable\n",
    "Nu, possiblePolicies = F.constructNu(Ns,Nf,cntrl_fac_idx,policy_horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action-Perception Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize history of beliefs, hidden states, and observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set current hidden state to be the initial state sampled above\n",
    "s = initState\n",
    "\n",
    "# set up some variables to store history of actions, etc.\n",
    "actions_hist = np.zeros( (Nu[0],T) )\n",
    "states_hist = np.zeros( (Ns[0],T) )\n",
    "obs_hist = np.zeros( (No[0],T) )\n",
    "Qs_hist = np.zeros( (Ns[0],T) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(T):\n",
    "\n",
    "    #### SAMPLE AN OBSERVATION FROM THE GENERATIVE PROCESS ######\n",
    "    ps = A_GP.dot(s)\n",
    "    obs = ps.sample()\n",
    "\n",
    "    #### INVERT GENERATIVE MODEL TO INFER MOST LIKELY HIDDEN STATE ######\n",
    "    Qs = F.update_posterior_states(A_GM, obs, prior, return_numpy = False)\n",
    "\n",
    "    #### INFER THE MOST LIKELY POLICIES (USING EXPECTED FREE ENERGY ASSUMPTION) #####\n",
    "\n",
    "    Q_pi,EFE = F.update_posterior_policies(Qs, A_GM, pA, B_GM, pB, C, possiblePolicies, gamma = 16.0, return_numpy=True)\n",
    "\n",
    "    #### SAMPLE AN ACTION FROM THE POSTERIOR OVER CONTROLS, AND PERTURB THE GENERATIVE PROCESS USING THE SAMPLED ACTION #####\n",
    "    action = F.sample_action(Q_pi, possiblePolicies, Nu, sampling_type = 'marginal_action')\n",
    "    s = B_GP[:,:,action[0]].dot(s)\n",
    "\n",
    "    #### STORE VARIABLES IN HISTORY ####\n",
    "    actions_hist[action[0],t] = 1.0\n",
    "    states_hist[np.where(s)[0],t] = 1.0\n",
    "    obs_hist[obs,t] = 1.0\n",
    "    Qs_hist[:,t] = Qs.values[:,0].copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
