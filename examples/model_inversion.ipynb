{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Inference model inversion: T-Maze Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from copy import deepcopy\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pymdp.jax.agent import Agent\n",
    "from pymdp.envs import TMazeEnv\n",
    "from pymdp import utils \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "Here we consider an agent navigating a three-armed 'T-maze,' with the agent starting in a central location of the maze. The bottom arm of the maze contains an informative cue, which signals in which of the two top arms ('Left' or 'Right', the ends of the 'T') a reward is likely to be found. \n",
    "\n",
    "### Hidden states\n",
    "\n",
    "The T-Maze environment is comprised of two hidden state factors:\n",
    "\n",
    "- `Location`: a $4$-dimensional vector that encodes the current position of the agent, and can take the following values: {`CENTER`, `RIGHT ARM`, `LEFT ARM`, or `CUE LOCATION`}. For example, if the agent is in the `CUE LOCATION`, the current state of this factor would be $s_1 = [0 \\ 0 \\ 0 \\ 1]$.\n",
    "\n",
    "-`Reward Condition`: a $ 1 \\ x \\ 2 $ vector that encodes the reward condition of the trial: {`Reward on Right`, or `Reward on Left`}.  A trial where the condition is reward is `Reward on Left` is thus encoded as the state $s_2 = [0 \\ 1]$.\n",
    "\n",
    "The environment is designed such that when the agent is located in the `RIGHT ARM` and the reward condition is `Reward on Right`, the agent has a specified probability $a$ (where $a > 0.5$) of receiving a reward, and a low probability $b = 1 - a$ of receiving a 'loss' (we can think of this as an aversive or unpreferred stimulus). If the agent is in the `LEFT ARM` for the same reward condition, the reward probabilities are swapped, and the agent experiences loss with probability $a$, and reward with lower probability $b = 1 - a$. These reward contingencies are intuitively swapped for the `Reward on Left` condition. \n",
    "\n",
    "### Observations\n",
    "\n",
    "The agent is equipped with three sensory channels or observation modalities: `Location`, `Reward`, and `Cue`. \n",
    "\n",
    "-  `Location`: a $4$-dimensional observation that encodes the sensed position of the agent, and can take the same values as the `Location` hidden state factor.\n",
    "  \n",
    "- `Reward` : a $3$-dimensional observation that can take the values `No Reward`, `Reward` or `Loss`.  The `No Reward` (index 0) observation is  observed whenever the agent isn't occupying one of the two T-maze arms (the right or left arms). The `Reward` (index 1) and `Loss` (index 2) observations are observed in the right and left arms of the T-maze, with associated probabilities that depend on the reward condition (i.e. on the value of the second hidden state factor).\n",
    "\n",
    "- `Cue`: a $2$-dimensional observation that can take the values `Cue Right` or `Cue Left`. This observation signals the reward condition of the trial, and therefore in which arm the `Reward` observation is more probable. When the agent occupies the other two arms (the `RIGHT` or `LEFT` arms), the `Cue` observation will be `Cue Right` or `Cue Left` with equal probability. However (as we'll see below when we intialise the agent), the agent's beliefs about the likelihood mapping render these observations uninformative and irrelevant to state inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize environment\n",
    "Now we can initialize the T-maze environment using the built-in `TMazeEnv` class from the `pymdp.envs` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose reward probabilities $a$ and $b$, where $a$ and $b$ are the probabilities of reward / loss in the 'correct' arm, and the probabilities of loss / reward in the 'incorrect' arm. Which arm counts as 'correct' vs. 'incorrect' depends on the reward condition (state of the 2nd hidden state factor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_probabilities = [0.98, 0.02] # probabilities used in the original SPM T-maze demo\n",
    "env = TMazeEnv(reward_probs = reward_probabilities)\n",
    "A_gp = env.get_likelihood_dist()\n",
    "B_gp = env.get_transition_dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on Controllable (and Uncontrollable-) Transition Dynamics\n",
    "\n",
    "Importantly, some hidden state factors are _controllable_ by the agent, meaning that the probability of being in state $i$ at $t+1$ doesn't only depend on the state at $t$, but also on actions or _control states_. So now each transition likelihood encodes conditional probability distributions over states at $t+1$, where the conditioning variables are both the states at $t-1$ _and_ the actions at $t-1$. This extra conditioning on actions is encoded via an optional third dimension to each factor-specific `B` matrix.\n",
    "\n",
    "For example, in our case the first hidden state factor (`Location`) is under the control of the agent, which means the corresponding transition likelihoods `B[0]` are index-able by both previous state and action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The generative model\n",
    "Now we can move onto setting up the generative model of the agent - namely, the agent's beliefs about how hidden states give rise to observations, and how hidden states transition among eachother.\n",
    "\n",
    "In almost all MDPs, the critical building blocks of this generative model are the agent's representation of the observation likelihood, which we'll refer to as `A_gm`, and its representation of the transition likelihood, or `B_gm`. \n",
    "\n",
    "Here, we assume the agent has a veridical representation of the rules of the T-maze (namely, how hidden states cause observations) as well as its ability to control its own movements with certain consequences (i.e. 'noiseless' transitions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the generative model of each agent a copy of the true generative process likelihood array\n",
    "\n",
    "base_A_gm = deepcopy(A_gp) \n",
    "base_B_gm = deepcopy(B_gp) \n",
    "\n",
    "num_obs, num_states, num_modalities, num_factors = utils.get_model_dimensions(A=base_A_gm, B=base_B_gm)\n",
    "\n",
    "base_D_gm = utils.obj_array_uniform(num_states)\n",
    "base_D_gm[0] = utils.onehot(0, num_states[0])\n",
    "\n",
    "base_C_gm = utils.obj_array_zeros(num_obs)\n",
    "base_C_gm[1] = np.array([0., 3., -3.])\n",
    "\n",
    "num_actions = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_agents = 50  # number of different agents \n",
    "\n",
    "# construct all the generative models of all agents by copying the \"base\" generative model\n",
    "# we're putting the batch-dimension (here: `num_agents`) in the leading dimension of each modality- or factor-specific sub-array\n",
    "A_gm_all = [jnp.broadcast_to(jnp.array(a), (num_agents,) + a.shape) for a in base_A_gm]  # map the true observation likelihood to jax arrays\n",
    "B_gm_all = [jnp.broadcast_to(jnp.array(b), (num_agents,) + b.shape) for b in base_B_gm]  # map the true transition likelihood to jax arrays\n",
    "D_gm_all = [jnp.broadcast_to(jnp.array(d),  (num_agents,) + d.shape) for d in base_D_gm]\n",
    "C_gm_all = [jnp.broadcast_to(jnp.array(c),  (num_agents,) + c.shape) for c in base_C_gm]\n",
    "E_gm_all = jnp.ones((num_agents, num_actions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing the `Agent()` class\n",
    "\n",
    "In `pymdp`, we have abstracted much of the computations required for active inference into the `Agent()` class, a flexible object that can be used to store necessary aspects of the generative model, the agent's instantaneous observations and actions, and perform action / perception using functions like `Agent.infer_states` and `Agent.infer_policies`. \n",
    "\n",
    "An instance of `Agent` is straightforwardly initialized with a call to `Agent()` with a list of optional arguments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our call to `Agent()`, we need to constrain the default behavior with some of our T-Maze-specific needs. For example, we want to make sure that the agent's beliefs about transitions are constrained by the fact that it can only control the `Location` factor - _not_ the `Reward Condition` (which we assumed stationary across an epoch of time). Therefore we specify this using a list of indices that will be passed as the `control_fac_idx` argument of the `Agent()` constructor. \n",
    "\n",
    "Each element in the list specifies a hidden state factor (in terms of its index) that is controllable by the agent. Hidden state factors whose indices are _not_ in this list are assumed to be uncontrollable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "controllable_indices = [0] # this is a list of the indices of the hidden state factors that are controllable\n",
    "agent = Agent(A_gm_all, B_gm_all, C_gm_all, D_gm_all, E_gm_all, control_fac_idx=controllable_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTreeDef(CustomNode(Agent[(('A', 'B', 'C', 'D', 'E', 'gamma', 'qs', 'q_pi'), ('num_iter', 'num_obs', 'num_modalities', 'num_states', 'num_factors', 'num_controls', 'inference_algo', 'control_fac_idx', 'policy_len', 'policies', 'use_utility', 'use_states_info_gain', 'use_param_info_gain', 'action_selection'), (16, [4, 3, 2], 3, [4, 2], 2, [4, 1], 'VANILLA', [0], 1, DeviceArray([[[0, 0]],\n",
      "\n",
      "             [[1, 0]],\n",
      "\n",
      "             [[2, 0]],\n",
      "\n",
      "             [[3, 0]]], dtype=int32), True, True, False, 'deterministic'))], [[*, *, *], [*, *], [*, *, *], [*, *], *, *, None, None]))\n"
     ]
    }
   ],
   "source": [
    "import jax.tree_util as jtu\n",
    "\n",
    "vals, tree = jtu.tree_flatten(agent)\n",
    "\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Inference\n",
    "Now we can start off the T-maze with an initial observation and run active inference via a loop over a desired time interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "T = 5 # number of timesteps\n",
    "\n",
    "emp_prior = D_gm_all\n",
    "_obs = env.reset() # reset the environment and get an initial observation\n",
    "obs = jnp.broadcast_to(jnp.array(_obs), (num_agents, num_modalities)) # everyone gets the same initial observation\n",
    "\n",
    "agent_to_show = 1 # which agent to print the messages of over time\n",
    "\n",
    "# these are useful for displaying read-outs during the loop over time\n",
    "reward_conditions = [\"Right\", \"Left\"]\n",
    "location_observations = ['CENTER','RIGHT ARM','LEFT ARM','CUE LOCATION']\n",
    "reward_observations = ['No reward','Reward!','Loss!']\n",
    "cue_observations = ['Cue Right','Cue Left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan],\n",
       "             [nan, nan]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: understand why gradient returns nans for num_iter > 2\n",
    "\n",
    "agent = Agent(A_gm_all, B_gm_all, C_gm_all, D_gm_all, E_gm_all, control_fac_idx=controllable_indices, num_iter=3)\n",
    "def test(prior):\n",
    "    loc_prior = [emp_prior[0], prior]\n",
    "    qs = agent.infer_states(obs, loc_prior)\n",
    "\n",
    "    return jnp.log(qs[1]).sum()\n",
    "\n",
    "jax.grad(test)(emp_prior[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " === Starting experiment === \n",
      " Reward condition: Right, Observation: [CENTER, No reward, Cue Left]\n",
      "[Step 0] Action: [Move to CUE LOCATION]\n",
      "[Step 0] Observation: [CUE LOCATION,  No reward, Cue Right]\n",
      "[Step 1] Action: [Move to RIGHT ARM]\n",
      "[Step 1] Observation: [RIGHT ARM,  Reward!, Cue Right]\n",
      "[Step 2] Action: [Move to RIGHT ARM]\n",
      "[Step 2] Observation: [RIGHT ARM,  Reward!, Cue Left]\n",
      "[Step 3] Action: [Move to RIGHT ARM]\n",
      "[Step 3] Observation: [RIGHT ARM,  Reward!, Cue Left]\n",
      "[Step 4] Action: [Move to RIGHT ARM]\n",
      "[Step 4] Observation: [RIGHT ARM,  Reward!, Cue Left]\n"
     ]
    }
   ],
   "source": [
    "msg = \"\"\" === Starting experiment === \\n Reward condition: {}, Observation: [{}, {}, {}]\"\"\"\n",
    "print(msg.format(reward_conditions[env.reward_condition], location_observations[_obs[0]], reward_observations[_obs[1]], cue_observations[_obs[2]]))\n",
    "\n",
    "qs_list = []\n",
    "measurements = {'actions': [], 'outcomes': [obs]}\n",
    "for t in range(T):\n",
    "    qs = agent.infer_states(obs, emp_prior)\n",
    "    qs_list.append(qs.copy())\n",
    "\n",
    "    q_pi, efe = agent.infer_policies(qs)\n",
    "\n",
    "    actions = agent.sample_action(q_pi)\n",
    "    emp_prior = agent.update_empirical_prior(actions, qs)\n",
    "\n",
    "    measurements[\"actions\"].append( actions )\n",
    "    msg = \"\"\"[Step {}] Action: [Move to {}]\"\"\"\n",
    "    print(msg.format(t, location_observations[int(actions[agent_to_show, 0])]))\n",
    "\n",
    "    obs = []\n",
    "    for a in actions:\n",
    "        obs.append( jnp.array(env.step(list(a))) )\n",
    "    obs = jnp.stack(obs)\n",
    "    measurements[\"outcomes\"].append(obs)\n",
    "\n",
    "    msg = \"\"\"[Step {}] Observation: [{},  {}, {}]\"\"\"\n",
    "    print(msg.format(t, location_observations[obs[agent_to_show, 0]], reward_observations[obs[agent_to_show, 1]], cue_observations[obs[agent_to_show, 2]]))\n",
    "    \n",
    "measurements['actions'] = jnp.stack(measurements['actions']).astype(jnp.int32)\n",
    "measurements['outcomes'] = jnp.stack(measurements['outcomes'])\n",
    "measurements['outcomes'] = measurements['outcomes'][None, :T]\n",
    "measurements['actions'] = measurements['actions'][None]\n",
    "reward_condition_beliefs = jnp.stack([qs_i[1] for qs_i in qs_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f689defd4f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(reward_condition_beliefs[4], aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model inversion\n",
    "Define model likelihood given the observed sequence of actions and outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 50, 3)\n",
      "(1, 5, 50, 2)\n",
      "475 ms ± 7.64 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "497 ms ± 12.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "dict_keys(['actions', 'outcomes'])\n"
     ]
    }
   ],
   "source": [
    "import numpyro as npyro\n",
    "from jax import random\n",
    "from numpyro.infer import Predictive\n",
    "from pymdp.jax.likelihoods import aif_likelihood, evolve_trials\n",
    "\n",
    "print(measurements['outcomes'].shape)\n",
    "print(measurements['actions'].shape)\n",
    "\n",
    "Nb, Nt, Na, _ = measurements['actions'].shape\n",
    "\n",
    "xs = {'outcomes': measurements['outcomes'][0], 'actions': measurements['actions'][0]}\n",
    "evolve_trials(agent, xs)\n",
    "%timeit evolve_trials(agent, xs)\n",
    "\n",
    "rng_key = random.PRNGKey(0)\n",
    "\n",
    "with npyro.handlers.seed(rng_seed=0):\n",
    "    aif_likelihood(Nb, Nt, Na, measurements, agent)\n",
    "\n",
    "pred_samples = Predictive(aif_likelihood, num_samples=11)(rng_key, Nb, Nt, Na, measurements, agent)\n",
    "%timeit pred_samples = Predictive(aif_likelihood, num_samples=11)(rng_key, Nb, Nt, Na, measurements, agent)\n",
    "print(pred_samples.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro as npyro\n",
    "import numpyro.distributions as dist\n",
    "from jax import nn, lax, vmap\n",
    "\n",
    "@vmap\n",
    "def trans_params(z):\n",
    "\n",
    "    a = nn.sigmoid(z[0])\n",
    "    lam = nn.softplus(z[1])\n",
    "    d = nn.sigmoid(z[2])\n",
    "\n",
    "    A = lax.stop_gradient([jnp.array(x) for x in list(base_A_gm)])\n",
    "\n",
    "    middle_matrix1 = jnp.array([[0., 0.], [a, 1-a], [1-a, a]])\n",
    "    middle_matrix2 = jnp.array([[0., 0.], [1-a, a], [a, 1-a]])\n",
    "\n",
    "    side_vector = jnp.stack([jnp.array([1.0, 0., 0.]), jnp.array([1.0, 0., 0.])], -1)\n",
    "\n",
    "    A[1] = jnp.stack([side_vector, middle_matrix1, middle_matrix2, side_vector], -2)\n",
    "    \n",
    "    C = [\n",
    "        jnp.zeros(4),\n",
    "        lam * jnp.array([0., 1., -1.]),\n",
    "        jnp.zeros(2)\n",
    "    ]\n",
    "\n",
    "    D = [nn.one_hot(0, 4), jnp.array([d, 1-d])]\n",
    "\n",
    "    E = jnp.ones(4)/4\n",
    "\n",
    "    params = {\n",
    "        'A': A,\n",
    "        'B': lax.stop_gradient([jnp.array(x) for x in list(base_B_gm)]),\n",
    "        'C': C,\n",
    "        'D': D,\n",
    "        'E': E\n",
    "    }\n",
    "\n",
    "    return  params, a, lam, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603 ms ± 8.16 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "dict_keys(['a', 'actions', 'd', 'lambda', 'outcomes', 'z'])\n"
     ]
    }
   ],
   "source": [
    "def model(data, num_blocks, num_steps, num_agents, num_params=3):\n",
    "    with npyro.plate('agents', num_agents):\n",
    "        z = npyro.sample('z', dist.Normal(0., 1.).expand([num_params]).to_event(1))\n",
    "        params, a, lmbd, d = trans_params(z)\n",
    "        # register parameter values\n",
    "        npyro.deterministic('a', a)\n",
    "        npyro.deterministic('lambda', lmbd)\n",
    "        npyro.deterministic('d', d)\n",
    "\n",
    "    agents = Agent(\n",
    "        params['A'], \n",
    "        params['B'], \n",
    "        params['C'], \n",
    "        params['D'], \n",
    "        params['E'], \n",
    "        control_fac_idx=controllable_indices,\n",
    "        num_iter=2\n",
    "    )\n",
    "\n",
    "    aif_likelihood(num_blocks, num_steps, num_agents, data, agents)\n",
    "    \n",
    "with npyro.handlers.seed(rng_seed=101111):\n",
    "    model(measurements, Nb, Nt, Na)\n",
    "\n",
    "%timeit pred_samples = Predictive(model, num_samples=11)(rng_key, measurements, Nb, Nt, Na)\n",
    "pred_samples = Predictive(model, num_samples=11)(rng_key, measurements, Nb, Nt, Na)\n",
    "print(pred_samples.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot find valid initial parameters. Please check your model again.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m mcmc \u001b[39m=\u001b[39m MCMC(kernel, num_warmup\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, num_samples\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, progress_bar\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m rng_key, _rng_key \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msplit(rng_key)\n\u001b[0;32m---> 11\u001b[0m mcmc\u001b[39m.\u001b[39;49mrun(_rng_key, measurements, Nb, Nt, Na)\n",
      "File \u001b[0;32m~/.conda/envs/pymdp/lib/python3.9/site-packages/numpyro/infer/mcmc.py:593\u001b[0m, in \u001b[0;36mMCMC.run\u001b[0;34m(self, rng_key, extra_fields, init_params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    591\u001b[0m map_args \u001b[39m=\u001b[39m (rng_key, init_state, init_params)\n\u001b[1;32m    592\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_chains \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 593\u001b[0m     states_flat, last_state \u001b[39m=\u001b[39m partial_map_fn(map_args)\n\u001b[1;32m    594\u001b[0m     states \u001b[39m=\u001b[39m tree_map(\u001b[39mlambda\u001b[39;00m x: x[jnp\u001b[39m.\u001b[39mnewaxis, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m], states_flat)\n\u001b[1;32m    595\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/pymdp/lib/python3.9/site-packages/numpyro/infer/mcmc.py:381\u001b[0m, in \u001b[0;36mMCMC._single_chain_mcmc\u001b[0;34m(self, init, args, kwargs, collect_fields)\u001b[0m\n\u001b[1;32m    379\u001b[0m rng_key, init_state, init_params \u001b[39m=\u001b[39m init\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m init_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     init_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msampler\u001b[39m.\u001b[39;49minit(\n\u001b[1;32m    382\u001b[0m         rng_key,\n\u001b[1;32m    383\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_warmup,\n\u001b[1;32m    384\u001b[0m         init_params,\n\u001b[1;32m    385\u001b[0m         model_args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    386\u001b[0m         model_kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[1;32m    387\u001b[0m     )\n\u001b[1;32m    388\u001b[0m sample_fn, postprocess_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_cached_fns()\n\u001b[1;32m    389\u001b[0m diagnostics \u001b[39m=\u001b[39m (\n\u001b[1;32m    390\u001b[0m     \u001b[39mlambda\u001b[39;00m x: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampler\u001b[39m.\u001b[39mget_diagnostics_str(x[\u001b[39m0\u001b[39m])\n\u001b[1;32m    391\u001b[0m     \u001b[39mif\u001b[39;00m rng_key\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    392\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    393\u001b[0m )  \u001b[39m# noqa: E731\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pymdp/lib/python3.9/site-packages/numpyro/infer/hmc.py:706\u001b[0m, in \u001b[0;36mHMC.init\u001b[0;34m(self, rng_key, num_warmup, init_params, model_args, model_kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[39m# vectorized\u001b[39;00m\n\u001b[1;32m    702\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     rng_key, rng_key_init_model \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mswapaxes(\n\u001b[1;32m    704\u001b[0m         vmap(random\u001b[39m.\u001b[39msplit)(rng_key), \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m\n\u001b[1;32m    705\u001b[0m     )\n\u001b[0;32m--> 706\u001b[0m init_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_state(\n\u001b[1;32m    707\u001b[0m     rng_key_init_model, model_args, model_kwargs, init_params\n\u001b[1;32m    708\u001b[0m )\n\u001b[1;32m    709\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_potential_fn \u001b[39mand\u001b[39;00m init_params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    710\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    711\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mValid value of `init_params` must be provided with\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m `potential_fn`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    712\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/pymdp/lib/python3.9/site-packages/numpyro/infer/hmc.py:652\u001b[0m, in \u001b[0;36mHMC._init_state\u001b[0;34m(self, rng_key, model_args, model_kwargs, init_params)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_init_state\u001b[39m(\u001b[39mself\u001b[39m, rng_key, model_args, model_kwargs, init_params):\n\u001b[1;32m    651\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 652\u001b[0m         init_params, potential_fn, postprocess_fn, model_trace \u001b[39m=\u001b[39m initialize_model(\n\u001b[1;32m    653\u001b[0m             rng_key,\n\u001b[1;32m    654\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model,\n\u001b[1;32m    655\u001b[0m             dynamic_args\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    656\u001b[0m             init_strategy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_strategy,\n\u001b[1;32m    657\u001b[0m             model_args\u001b[39m=\u001b[39;49mmodel_args,\n\u001b[1;32m    658\u001b[0m             model_kwargs\u001b[39m=\u001b[39;49mmodel_kwargs,\n\u001b[1;32m    659\u001b[0m             forward_mode_differentiation\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_mode_differentiation,\n\u001b[1;32m    660\u001b[0m         )\n\u001b[1;32m    661\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    662\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_fn, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sample_fn \u001b[39m=\u001b[39m hmc(\n\u001b[1;32m    663\u001b[0m                 potential_fn_gen\u001b[39m=\u001b[39mpotential_fn,\n\u001b[1;32m    664\u001b[0m                 kinetic_fn\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kinetic_fn,\n\u001b[1;32m    665\u001b[0m                 algo\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_algo,\n\u001b[1;32m    666\u001b[0m             )\n",
      "File \u001b[0;32m~/.conda/envs/pymdp/lib/python3.9/site-packages/numpyro/infer/util.py:698\u001b[0m, in \u001b[0;36minitialize_model\u001b[0;34m(rng_key, model, init_strategy, dynamic_args, model_args, model_kwargs, forward_mode_differentiation, validate_grad)\u001b[0m\n\u001b[1;32m    685\u001b[0m                             w\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39margs \u001b[39m=\u001b[39m (\n\u001b[1;32m    686\u001b[0m                                 \u001b[39m\"\u001b[39m\u001b[39mSite \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    687\u001b[0m                                     site[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m], w\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    688\u001b[0m                                 ),\n\u001b[1;32m    689\u001b[0m                             ) \u001b[39m+\u001b[39m w\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39margs[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    690\u001b[0m                             warnings\u001b[39m.\u001b[39mshowwarning(\n\u001b[1;32m    691\u001b[0m                                 w\u001b[39m.\u001b[39mmessage,\n\u001b[1;32m    692\u001b[0m                                 w\u001b[39m.\u001b[39mcategory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    696\u001b[0m                                 line\u001b[39m=\u001b[39mw\u001b[39m.\u001b[39mline,\n\u001b[1;32m    697\u001b[0m                             )\n\u001b[0;32m--> 698\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    699\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCannot find valid initial parameters. Please check your model again.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    700\u001b[0m         )\n\u001b[1;32m    701\u001b[0m \u001b[39mreturn\u001b[39;00m ModelInfo(\n\u001b[1;32m    702\u001b[0m     ParamInfo(init_params, pe, grad), potential_fn, postprocess_fn, model_trace\n\u001b[1;32m    703\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot find valid initial parameters. Please check your model again."
     ]
    }
   ],
   "source": [
    "# inference with NUTS and MCMC\n",
    "from numpyro.infer import NUTS, MCMC\n",
    "from numpyro.infer import init_to_feasible, init_to_sample, init_to_median\n",
    "\n",
    "rng_key = random.PRNGKey(0)\n",
    "kernel = NUTS(model, init_strategy=init_to_median)\n",
    "\n",
    "mcmc = MCMC(kernel, num_warmup=1000, num_samples=1000, progress_bar=True)\n",
    "\n",
    "rng_key, _rng_key = random.split(rng_key)\n",
    "mcmc.run(_rng_key, measurements, Nb, Nt, Na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "az.style.use('arviz-darkgrid')\n",
    "\n",
    "coords = {\n",
    "    'idx': jnp.arange(num_agents),\n",
    "    'vars': jnp.arange(3), \n",
    "}\n",
    "dims = {'z': [\"idx\", \"vars\"], 'd': [\"idx\"], 'lambda': [\"idx\"], 'a': [\"idx\"]}\n",
    "data_kwargs = {\n",
    "    \"dims\": dims,\n",
    "    \"coords\": coords,\n",
    "}\n",
    "data_mcmc = az.from_numpyro(posterior=mcmc, **data_kwargs)\n",
    "az.plot_trace(data_mcmc, kind=\"rank_bars\", var_names=['d', 'lambda', 'a']);\n",
    "\n",
    "#TODO: maybe plot real values on top of samples from the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot find valid initial parameters. Please check your model again.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [36], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m svi \u001b[39m=\u001b[39m SVI(model, guide, optimizer, Trace_ELBO(num_particles\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m))\n\u001b[1;32m     10\u001b[0m rng_key, _rng_key \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msplit(rng_key)\n\u001b[0;32m---> 11\u001b[0m svi_res \u001b[39m=\u001b[39m svi\u001b[39m.\u001b[39;49mrun(_rng_key, num_iters, measurements, Nb, Nt, Na, progress_bar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.conda/envs/pymdp/lib/python3.9/site-packages/numpyro/infer/svi.py:342\u001b[0m, in \u001b[0;36mSVI.run\u001b[0;34m(self, rng_key, num_steps, progress_bar, stable_update, init_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[39mreturn\u001b[39;00m svi_state, loss\n\u001b[1;32m    341\u001b[0m \u001b[39mif\u001b[39;00m init_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 342\u001b[0m     svi_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit(rng_key, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    343\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    344\u001b[0m     svi_state \u001b[39m=\u001b[39m init_state\n",
      "File \u001b[0;32m~/.conda/envs/pymdp/lib/python3.9/site-packages/numpyro/infer/svi.py:180\u001b[0m, in \u001b[0;36mSVI.init\u001b[0;34m(self, rng_key, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m model_init \u001b[39m=\u001b[39m seed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, model_seed)\n\u001b[1;32m    179\u001b[0m guide_init \u001b[39m=\u001b[39m seed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mguide, guide_seed)\n\u001b[0;32m--> 180\u001b[0m guide_trace \u001b[39m=\u001b[39m trace(guide_init)\u001b[39m.\u001b[39;49mget_trace(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstatic_kwargs)\n\u001b[1;32m    181\u001b[0m model_trace \u001b[39m=\u001b[39m trace(replay(model_init, guide_trace))\u001b[39m.\u001b[39mget_trace(\n\u001b[1;32m    182\u001b[0m     \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatic_kwargs\n\u001b[1;32m    183\u001b[0m )\n\u001b[1;32m    184\u001b[0m params \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/.conda/envs/pymdp/lib/python3.9/site-packages/numpyro/handlers.py:171\u001b[0m, in \u001b[0;36mtrace.get_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_trace\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    164\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[39m    Run the wrapped callable and return the recorded trace.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39m    :return: `OrderedDict` containing the execution trace.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m     \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    172\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrace\n",
      "File \u001b[0;32m~/.conda/envs/pymdp/lib/python3.9/site-packages/numpyro/primitives.py:105\u001b[0m, in \u001b[0;36mMessenger.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/pymdp/lib/python3.9/site-packages/numpyro/primitives.py:105\u001b[0m, in \u001b[0;36mMessenger.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/pymdp/lib/python3.9/site-packages/numpyro/infer/autoguide.py:559\u001b[0m, in \u001b[0;36mAutoContinuous.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    557\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprototype_trace \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    558\u001b[0m         \u001b[39m# run model to inspect the model structure\u001b[39;00m\n\u001b[0;32m--> 559\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_prototype(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    561\u001b[0m     latent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sample_latent(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    563\u001b[0m     \u001b[39m# unpack continuous latent samples\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pymdp/lib/python3.9/site-packages/numpyro/infer/autoguide.py:521\u001b[0m, in \u001b[0;36mAutoContinuous._setup_prototype\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_setup_prototype\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 521\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_setup_prototype(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    522\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_latent, shape_dict \u001b[39m=\u001b[39m _ravel_dict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_locs)\n\u001b[1;32m    523\u001b[0m     unpack_latent \u001b[39m=\u001b[39m partial(_unravel_dict, shape_dict\u001b[39m=\u001b[39mshape_dict)\n",
      "File \u001b[0;32m~/.conda/envs/pymdp/lib/python3.9/site-packages/numpyro/infer/autoguide.py:156\u001b[0m, in \u001b[0;36mAutoGuide._setup_prototype\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m rng_key \u001b[39m=\u001b[39m numpyro\u001b[39m.\u001b[39mprng_key()\n\u001b[1;32m    150\u001b[0m \u001b[39mwith\u001b[39;00m handlers\u001b[39m.\u001b[39mblock():\n\u001b[1;32m    151\u001b[0m     (\n\u001b[1;32m    152\u001b[0m         init_params,\n\u001b[1;32m    153\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_potential_fn_gen,\n\u001b[1;32m    154\u001b[0m         postprocess_fn_gen,\n\u001b[1;32m    155\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprototype_trace,\n\u001b[0;32m--> 156\u001b[0m     ) \u001b[39m=\u001b[39m initialize_model(\n\u001b[1;32m    157\u001b[0m         rng_key,\n\u001b[1;32m    158\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel,\n\u001b[1;32m    159\u001b[0m         init_strategy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_loc_fn,\n\u001b[1;32m    160\u001b[0m         dynamic_args\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    161\u001b[0m         model_args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    162\u001b[0m         model_kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    164\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_potential_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_potential_fn_gen(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m postprocess_fn \u001b[39m=\u001b[39m postprocess_fn_gen(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/pymdp/lib/python3.9/site-packages/numpyro/infer/util.py:698\u001b[0m, in \u001b[0;36minitialize_model\u001b[0;34m(rng_key, model, init_strategy, dynamic_args, model_args, model_kwargs, forward_mode_differentiation, validate_grad)\u001b[0m\n\u001b[1;32m    685\u001b[0m                             w\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39margs \u001b[39m=\u001b[39m (\n\u001b[1;32m    686\u001b[0m                                 \u001b[39m\"\u001b[39m\u001b[39mSite \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    687\u001b[0m                                     site[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m], w\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    688\u001b[0m                                 ),\n\u001b[1;32m    689\u001b[0m                             ) \u001b[39m+\u001b[39m w\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39margs[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    690\u001b[0m                             warnings\u001b[39m.\u001b[39mshowwarning(\n\u001b[1;32m    691\u001b[0m                                 w\u001b[39m.\u001b[39mmessage,\n\u001b[1;32m    692\u001b[0m                                 w\u001b[39m.\u001b[39mcategory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    696\u001b[0m                                 line\u001b[39m=\u001b[39mw\u001b[39m.\u001b[39mline,\n\u001b[1;32m    697\u001b[0m                             )\n\u001b[0;32m--> 698\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    699\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCannot find valid initial parameters. Please check your model again.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    700\u001b[0m         )\n\u001b[1;32m    701\u001b[0m \u001b[39mreturn\u001b[39;00m ModelInfo(\n\u001b[1;32m    702\u001b[0m     ParamInfo(init_params, pe, grad), potential_fn, postprocess_fn, model_trace\n\u001b[1;32m    703\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot find valid initial parameters. Please check your model again."
     ]
    }
   ],
   "source": [
    "# inference with SVI and autoguides\n",
    "import optax\n",
    "from numpyro.infer import SVI, Trace_ELBO, Predictive\n",
    "from numpyro.infer.autoguide import AutoMultivariateNormal\n",
    "\n",
    "num_iters = 1000\n",
    "guide = AutoMultivariateNormal(model)\n",
    "optimizer = npyro.optim.optax_to_numpyro(optax.chain(optax.adabelief(1e-3)))\n",
    "svi = SVI(model, guide, optimizer, Trace_ELBO(num_particles=10))\n",
    "rng_key, _rng_key = random.split(rng_key)\n",
    "svi_res = svi.run(_rng_key, num_iters, measurements, Nb, Nt, Na, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "plt.plot(svi_res.losses)\n",
    "plt.ylabel('Variational free energy');\n",
    "plt.xlabel('iter step');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_key, _rng_key = random.split(rng_key)\n",
    "pred = Predictive(\n",
    "    model, \n",
    "    guide=guide, \n",
    "    params=svi_res.params, \n",
    "    num_samples=1000, \n",
    "    return_sites=[\"d\", \"a\", \"lambda\"]\n",
    ")\n",
    "post_sample = pred(_rng_key, measurements, Nb, Nt, Na)\n",
    "\n",
    "for key in post_sample:\n",
    "    post_sample[key] = jnp.expand_dims(post_sample[key], 0)\n",
    "\n",
    "data_svi = az.convert_to_inference_data(post_sample, group=\"posterior\", **data_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = az.plot_forest(\n",
    "    [data_mcmc, data_svi],\n",
    "    model_names = [\"nuts\", \"svi\"],\n",
    "    kind='forestplot',\n",
    "    var_names=['d', 'lambda', 'a'],\n",
    "    coords={\"idx\": 0},\n",
    "    combined=True,\n",
    "    figsize=(20, 6)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('pymdp_env3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "32c08a4ac355ebac62cad37715f1d18a3925a14af2b6a4a96942ab426da83c5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
