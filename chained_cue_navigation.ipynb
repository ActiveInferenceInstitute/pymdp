{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.animation as animation \n",
    "\n",
    "path = pathlib.Path(os.getcwd())\n",
    "sys.path.append(str(path) + '/')\n",
    "\n",
    "from pymdp.agent import Agent\n",
    "from pymdp import utils, maths\n",
    "\n",
    "from IPython.display import HTML, Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dimensionalities of the generative model and environment\n",
    "\n",
    "grid_dims = [5, 7] # dimensions of the grid\n",
    "num_grid_points = np.prod(grid_dims)\n",
    "\n",
    "# create a look-up table mapping linear indices to (y, x) tuples\n",
    "grid = np.arange(num_grid_points).reshape(grid_dims)\n",
    "it = np.nditer(grid, flags=[\"multi_index\"])\n",
    "\n",
    "loc_list = []\n",
    "while not it.finished:\n",
    "    loc_list.append(it.multi_index)\n",
    "    it.iternext()\n",
    "\n",
    "cue1_location = (2, 0)\n",
    "# cue2_locations = [(1, 3), (1, 5), (3, 3), (3, 5)]\n",
    "cue2_locations = [(0, 2), (1, 3), (3, 3), (4, 2)]\n",
    "\n",
    "reward_conditions = [\"TOP\", \"BOTTOM\"]\n",
    "# reward_locations = [(0, 4), (4, 4)]\n",
    "reward_locations = [(1, 5), (3, 5)]\n",
    "\n",
    "num_states = [num_grid_points, len(cue2_locations), len(reward_conditions)]\n",
    "\n",
    "cue1_names = ['Null', 'Cue 1', 'Cue 2', 'Cue 3', 'Cue 4'] # different possible cue identities at cue1 location\n",
    "cue2_names = ['Null', 'reward_on_top', 'reward_on_bottom']\n",
    "\n",
    "reward_names = ['Null', '+5', '-10']\n",
    "\n",
    "num_obs = [num_grid_points, len(cue1_names), len(cue2_names), len(reward_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A matrix\n",
    "A_m_shapes = [ [o_dim] + num_states for o_dim in num_obs]\n",
    "A = utils.obj_array_zeros(A_m_shapes)\n",
    "\n",
    "# make the location observation only depend on the location state (proprioceptive observation modality)\n",
    "A[0] = np.tile(np.expand_dims(np.eye(num_grid_points), (-2, -1)), (1, 1, num_states[1], num_states[2]))\n",
    "\n",
    "# make the cue1 observation depend on the location (being at cue1_location) and the true location of cue2\n",
    "A[1][0,:,:,:] = 1.0 # default makes Null the most likely observation everywhere\n",
    "\n",
    "for i, cue_loc2_i in enumerate(cue2_locations):\n",
    "    A[1][0,loc_list.index(cue1_location),i,:] = 0.0\n",
    "    A[1][i+1,loc_list.index(cue1_location),i,:] = 1.0\n",
    "\n",
    "# make the cue2 observation depend on the location (being at the correct cue2_location) and the reward condition\n",
    "A[2][0,:,:,:] = 1.0 # default makes Null the most likely observation everywhere\n",
    "\n",
    "for i, cue_loc2_i in enumerate(cue2_locations):\n",
    "\n",
    "    # if the cue2-location is the one you're currently at, then you get a signal about where the reward is\n",
    "    A[2][0,loc_list.index(cue_loc2_i),i,:] = 0.0 \n",
    "    A[2][1,loc_list.index(cue_loc2_i),i,0] = 1.0\n",
    "    A[2][2,loc_list.index(cue_loc2_i),i,1] = 1.0\n",
    "    \n",
    "# make the reward observation depend on the location (being at reward location) and the reward condition\n",
    "A[3][0,:,:,:] = 1.0 # default makes Null the most likely observation everywhere\n",
    "\n",
    "A[3][0,loc_list.index(reward_locations[0]),:,:] = 0.0\n",
    "A[3][1,loc_list.index(reward_locations[0]),:,0] = 1.0\n",
    "A[3][2,loc_list.index(reward_locations[0]),:,1] = 1.0\n",
    "\n",
    "A[3][0,loc_list.index(reward_locations[1]),:,:] = 0.0\n",
    "A[3][1,loc_list.index(reward_locations[1]),:,1] = 1.0\n",
    "A[3][2,loc_list.index(reward_locations[1]),:,0] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B matrix\n",
    "\n",
    "num_controls = [5, 1, 1]\n",
    "B_f_shapes = [ [ns, ns, num_controls[f]] for f, ns in enumerate(num_states)]\n",
    "\n",
    "B = utils.obj_array_zeros(B_f_shapes)\n",
    "actions = [\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\", \"STAY\"]\n",
    "\n",
    "for action_id, action_label in enumerate(actions):\n",
    "\n",
    "  for curr_state, grid_location in enumerate(loc_list):\n",
    "\n",
    "    y, x = grid_location\n",
    "\n",
    "    if action_label == \"UP\":\n",
    "      next_y = y - 1 if y > 0 else y \n",
    "      next_x = x\n",
    "    elif action_label == \"DOWN\":\n",
    "      next_y = y + 1 if y < (grid_dims[0]-1) else y \n",
    "      next_x = x\n",
    "    elif action_label == \"LEFT\":\n",
    "      next_x = x - 1 if x > 0 else x \n",
    "      next_y = y\n",
    "    elif action_label == \"RIGHT\":\n",
    "      next_x = x + 1 if x < (grid_dims[1]-1) else x \n",
    "      next_y = y\n",
    "    elif action_label == \"STAY\":\n",
    "      next_x = x\n",
    "      next_y = y\n",
    "\n",
    "    new_location = (next_y, next_x)\n",
    "    next_state = loc_list.index(new_location)\n",
    "    B[0][next_state, curr_state, action_id] = 1.0\n",
    "\n",
    "B[1][:,:,0] = np.eye(num_states[1])\n",
    "B[2][:,:,0] = np.eye(num_states[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C vector\n",
    "C = utils.obj_array_zeros(num_obs)\n",
    "\n",
    "C[3][1] = 2.0\n",
    "C[3][2] = -4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D vector\n",
    "D = utils.obj_array_uniform(num_states)\n",
    "D[0] = utils.onehot(loc_list.index((2,2)), num_grid_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting location is (4, 0), Reward condition is TOP, cue is located in Cue 1\n"
     ]
    }
   ],
   "source": [
    "class GridWorldEnv():\n",
    "    \n",
    "    def __init__(self,starting_loc = (4,0), cue1_loc = (2, 0), cue2 = 'Cue 1', reward_condition = 'TOP'):\n",
    "\n",
    "        self.init_loc = starting_loc\n",
    "        self.current_location = self.init_loc\n",
    "\n",
    "        self.cue1_loc = cue1_loc\n",
    "        self.cue2_name = cue2\n",
    "        self.cue2_loc_names = ['Cue 1', 'Cue 2', 'Cue 3', 'Cue 4']\n",
    "        self.cue2_loc = cue2_locations[self.cue2_loc_names.index(self.cue2_name)]\n",
    "\n",
    "        self.reward_condition = reward_condition\n",
    "        print(f'Starting location is {self.init_loc}, Reward condition is {self.reward_condition}, cue is located in {self.cue2_name}')\n",
    "    \n",
    "    def step(self,action_label):\n",
    "\n",
    "        (Y, X) = self.current_location\n",
    "\n",
    "        if action_label == \"UP\": \n",
    "          \n",
    "          Y_new = Y - 1 if Y > 0 else Y\n",
    "          X_new = X\n",
    "\n",
    "        elif action_label == \"DOWN\": \n",
    "\n",
    "          Y_new = Y + 1 if Y < (grid_dims[0]-1) else Y\n",
    "          X_new = X\n",
    "\n",
    "        elif action_label == \"LEFT\": \n",
    "          Y_new = Y\n",
    "          X_new = X - 1 if X > 0 else X\n",
    "\n",
    "        elif action_label == \"RIGHT\": \n",
    "          Y_new = Y\n",
    "          X_new = X +1 if X < (grid_dims[1]-1) else X\n",
    "\n",
    "        elif action_label == \"STAY\":\n",
    "          Y_new, X_new = Y, X \n",
    "        \n",
    "        self.current_location = (Y_new, X_new) # store the new grid location\n",
    "\n",
    "        loc_obs = self.current_location # agent always directly observes the grid location they're in \n",
    "\n",
    "        if self.current_location == self.cue1_loc:\n",
    "          cue1_obs = self.cue2_name\n",
    "        else:\n",
    "          cue1_obs = 'Null'\n",
    "\n",
    "        if self.current_location == self.cue2_loc:\n",
    "          cue2_obs = cue2_names[reward_conditions.index(self.reward_condition)+1]\n",
    "        else:\n",
    "          cue2_obs = 'Null'\n",
    "        \n",
    "        if self.current_location == reward_locations[0]:\n",
    "          if self.reward_condition == 'TOP':\n",
    "            reward_obs = '+5'\n",
    "          else:\n",
    "            reward_obs = '-10'\n",
    "        elif self.current_location == reward_locations[1]:\n",
    "          if self.reward_condition == 'BOTTOM':\n",
    "            reward_obs = '+5'\n",
    "          else:\n",
    "            reward_obs = '-10'\n",
    "        else:\n",
    "          reward_obs = 'Null'\n",
    "\n",
    "        return loc_obs, cue1_obs, cue2_obs, reward_obs\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_location = self.init_loc\n",
    "        print(f'Re-initialized location to {self.init_loc}')\n",
    "        loc_obs = self.current_location\n",
    "        cue1_obs = 'Null'\n",
    "        cue2_obs = 'Null'\n",
    "        reward_obs = 'Null'\n",
    "\n",
    "        return loc_obs, cue1_obs, cue2_obs, reward_obs\n",
    "    \n",
    "env = GridWorldEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_agent = Agent(A = A, B = B, C = C, D = D, policy_len = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting location is (2, 2), Reward condition is TOP, cue is located in Cue 3\n",
      "Re-initialized location to (2, 2)\n",
      "Location at time 1: (2, 1)\n",
      "Cue1 observation at time 1: Null\n",
      "Cue2 observation at time 1: Null\n",
      "Reward at time 1: Null\n",
      "Location at time 2: (2, 0)\n",
      "Cue1 observation at time 2: Cue 3\n",
      "Cue2 observation at time 2: Null\n",
      "Reward at time 2: Null\n",
      "Location at time 3: (2, 1)\n",
      "Cue1 observation at time 3: Null\n",
      "Cue2 observation at time 3: Null\n",
      "Reward at time 3: Null\n",
      "Location at time 4: (2, 2)\n",
      "Cue1 observation at time 4: Null\n",
      "Cue2 observation at time 4: Null\n",
      "Reward at time 4: Null\n",
      "Location at time 5: (3, 2)\n",
      "Cue1 observation at time 5: Null\n",
      "Cue2 observation at time 5: Null\n",
      "Reward at time 5: Null\n",
      "Location at time 6: (3, 3)\n",
      "Cue1 observation at time 6: Null\n",
      "Cue2 observation at time 6: reward_on_top\n",
      "Reward at time 6: Null\n",
      "Location at time 7: (2, 3)\n",
      "Cue1 observation at time 7: Null\n",
      "Cue2 observation at time 7: Null\n",
      "Reward at time 7: Null\n",
      "Location at time 8: (2, 4)\n",
      "Cue1 observation at time 8: Null\n",
      "Cue2 observation at time 8: Null\n",
      "Reward at time 8: Null\n",
      "Location at time 9: (1, 4)\n",
      "Cue1 observation at time 9: Null\n",
      "Cue2 observation at time 9: Null\n",
      "Reward at time 9: Null\n",
      "Location at time 10: (1, 5)\n",
      "Cue1 observation at time 10: Null\n",
      "Cue2 observation at time 10: Null\n",
      "Reward at time 10: +5\n"
     ]
    }
   ],
   "source": [
    "my_env = GridWorldEnv(starting_loc = (2,2), cue1_loc = (2, 0), cue2 = 'Cue 3', reward_condition = 'TOP')\n",
    "loc_obs, cue1_obs, cue2_obs, reward_obs = my_env.reset()\n",
    "  \n",
    "history_of_locs = [loc_obs]\n",
    "history_of_beliefs = []\n",
    "obs = [loc_list.index(loc_obs), cue1_names.index(cue1_obs), cue2_names.index(cue2_obs), reward_names.index(reward_obs)]\n",
    "for t in range(10):\n",
    "\n",
    "    qs = my_agent.infer_states(obs)\n",
    "    # print(f'Beliefs about own location at time {t}: {qs[0].round(3)}')\n",
    "    # print(f'Beliefs about cue2 location at time {t}: {qs[1].round(3)}')\n",
    "    # print(f'Beliefs about reward condition at time {t}: {qs[2].round(3)}')\n",
    "\n",
    "    history_of_beliefs.append(qs)\n",
    "\n",
    "    my_agent.infer_policies()\n",
    "    chosen_action_id = my_agent.sample_action()\n",
    "\n",
    "    movement_id = int(chosen_action_id[0])\n",
    "\n",
    "    choice_action = actions[movement_id]\n",
    "\n",
    "    loc_obs, cue1_obs, cue2_obs, reward_obs = my_env.step(choice_action)\n",
    "\n",
    "    obs = [loc_list.index(loc_obs), cue1_names.index(cue1_obs), cue2_names.index(cue2_obs), reward_names.index(reward_obs)]\n",
    "\n",
    "    history_of_locs.append(loc_obs)\n",
    "\n",
    "    print(f'Location at time {t+1}: {loc_obs}')\n",
    "    print(f'Cue1 observation at time {t+1}: {cue1_obs}')\n",
    "    print(f'Cue2 observation at time {t+1}: {cue2_obs}')\n",
    "    print(f'Reward at time {t+1}: {reward_obs}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1.]\n",
      "[0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "print(history_of_beliefs[4][1].round(3))\n",
    "print(history_of_beliefs[4][2].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 2),\n",
       " (2, 1),\n",
       " (2, 0),\n",
       " (2, 1),\n",
       " (2, 2),\n",
       " (3, 2),\n",
       " (3, 3),\n",
       " (2, 3),\n",
       " (2, 4),\n",
       " (1, 4),\n",
       " (1, 5)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_of_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2],\n",
       "       [2, 1],\n",
       "       [2, 0],\n",
       "       [2, 1],\n",
       "       [2, 2],\n",
       "       [3, 2],\n",
       "       [3, 3],\n",
       "       [2, 3],\n",
       "       [2, 4],\n",
       "       [1, 4],\n",
       "       [1, 5]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(history_of_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "h = sns.heatmap(0.1 + np.zeros(grid_dims), cmap='viridis', vmax=1., vmin=0.0, linewidth = 20.0, cbar=False, ax=ax)\n",
    "\n",
    "img1 = plt.imread('mouse_img.png')\n",
    "im1 = OffsetImage(img1, zoom=0.042)\n",
    "\n",
    "ab1 = AnnotationBbox(im1, (history_of_locs[0][1] - 0.5, history_of_locs[0][0] + 0.5), xycoords='data', frameon=False)\n",
    "an1 = ax.add_artist(ab1)\n",
    "\n",
    "an1.xy = (history_of_locs[1][1] - 0.5, history_of_locs[1][0] + 0.5)\n",
    "an1.xybox = (history_of_locs[1][1] - 0.5, history_of_locs[1][0] + 0.5)\n",
    "\n",
    "def init():\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    sns.despine(top=True, right=True, left=True, bottom=True)\n",
    "    fig.tight_layout()\n",
    "    return h, an1\n",
    "\n",
    "def update(frame):\n",
    "    ydata1, xdata1 = frame\n",
    "    an1.xy = (xdata1 - 0.5, ydata1 + 0.5)\n",
    "    an1.xybox = (xdata1 - 0.5, ydata1 + 0.5)\n",
    "\n",
    "    return h, an1\n",
    "\n",
    "anim = FuncAnimation(fig, update, frames=np.array(history_of_locs[1:]), init_func=init, blit=True)\n",
    "anim.save('demo_icons.gif', writer = 'imagemagick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# shape = (n_x, n_y)\n",
    "# loc = np.ravel_multi_index(seek_sequence[0], shape)\n",
    "\n",
    "\n",
    "# frames = np.concatenate([np.array(seek_sequence),\n",
    "#                          np.array(hide_sequence)], -1)\n",
    "\n",
    "# img1 = plt.imread('mouse_img.png')\n",
    "# im1 = OffsetImage(img1, zoom=0.3)\n",
    "\n",
    "# ab1 = AnnotationBbox(im1, (frames[0][1], frames[0][0]), xycoords='data', frameon=False)\n",
    "# an1 = ax.add_artist(ab1)\n",
    "\n",
    "# ab2 = AnnotationBbox(im2, (frames[0][-1], frames[0][-2]), xycoords='data', frameon=False)\n",
    "# an2 = ax.add_artist(ab2)\n",
    "\n",
    "# def init():\n",
    "#     ax.set_xticklabels([])\n",
    "#     ax.set_yticklabels([])\n",
    "#     sns.despine(top=True, right=True, left=True, bottom=True)\n",
    "#     fig.tight_layout()\n",
    "#     return h, an1, an2\n",
    "\n",
    "# def update(frame):\n",
    "#     ydata1, xdata1, ydata2, xdata2 = frame\n",
    "#     an1.xy = (xdata1, ydata1)\n",
    "#     an1.xybox = (xdata1, ydata1)\n",
    "\n",
    "#     an2.xy = (xdata2, ydata2)\n",
    "#     an2.xybox = (xdata2, ydata2)\n",
    "\n",
    "#     loc = np.ravel_multi_index((ydata1, xdata1), shape)\n",
    "#     A = As_h[2][1][..., loc].reshape(n_x, n_y)\n",
    "#     h.set_data(np.where(A == 1, 1, np.nan))\n",
    "\n",
    "#     return h, an1, an2\n",
    "\n",
    "# anim = FuncAnimation(fig, update, frames=frames, init_func=init, blit=True)\n",
    "# anim.save('demo_icons.gif', writer='imagemagick', fps=5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24ee14d9f6452059a99d44b6cbd71d1bb479b0539b0360a6a17428ecea9f0810"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('pymdp_env2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
