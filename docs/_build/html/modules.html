
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17: http://docutils.sourceforge.net/" />

    <title>Modules &#8212; pymdp 0.0.3 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/classic.css" />
    
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Welcome to pymdp’s documentation!" href="index.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="index.html" title="Welcome to pymdp’s documentation!"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">pymdp 0.0.3 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Modules</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <p>modules.rst</p>
<section id="module-pymdp.inference">
<span id="modules"></span><h1>Modules<a class="headerlink" href="#module-pymdp.inference" title="Permalink to this headline">¶</a></h1>
<section id="inference-py">
<h2>inference.py<a class="headerlink" href="#inference-py" title="Permalink to this headline">¶</a></h2>
<p>Functions for performing inference of hidden states in POMDP generative models</p>
<dl class="py function">
<dt class="sig sig-object py" id="pymdp.inference.average_states_over_policies">
<span class="sig-prename descclassname"><span class="pre">pymdp.inference.</span></span><span class="sig-name descname"><span class="pre">average_states_over_policies</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">qs_pi</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q_pi</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymdp.inference.average_states_over_policies" title="Permalink to this definition">¶</a></dt>
<dd><p>This function computes a expected posterior over hidden states with respect to the posterior over policies,
also known as the ‘Bayesian model average of states with respect to policies’.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>qs_pi</strong> (<em>numpy ndarray of dtype object</em>) – Posterior beliefs over hidden states for each policy. Nesting structure is policies, factors,
where e.g. <cite>qs_pi[p][f]</cite> stores the marginal belief about factor <cite>f</cite> under policy <cite>p</cite>.</p></li>
<li><p><strong>q_pi</strong> (<em>numpy ndarray</em>) – Posterior beliefs about policies where <cite>len(q_pi) = num_policies</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>qs_bma</strong> – Marginal posterior over hidden states for the current timepoint,
averaged across policies according to their posterior probability given by <cite>q_pi</cite></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy ndarray of dtype object</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymdp.inference.update_posterior_states">
<span class="sig-prename descclassname"><span class="pre">pymdp.inference.</span></span><span class="sig-name descname"><span class="pre">update_posterior_states</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymdp.inference.update_posterior_states" title="Permalink to this definition">¶</a></dt>
<dd><p>Update marginal posterior over hidden states using mean-field fixed point iteration
FPI or Fixed point iteration. See the following links for details:
<a class="reference external" href="http://www.cs.cmu.edu/~guestrin/Class/10708/recitations/r9/VI-view.pdf">http://www.cs.cmu.edu/~guestrin/Class/10708/recitations/r9/VI-view.pdf</a>,</p>
<blockquote>
<div><p>slides 13- 18</p>
</div></blockquote>
<dl class="simple">
<dt><a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.137.221&amp;rep=rep1&amp;type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.137.221&amp;rep=rep1&amp;type=pdf</a>,</dt><dd><p>slides 24 - 38</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>A</strong> (<em>numpy ndarray of dtype object</em>) – Sensory likelihood mapping or ‘observation model’, mapping from hidden states to observations. Each element <cite>A[m]</cite> of
stores an <cite>np.ndarray</cite> multidimensional array for observation modality <cite>m</cite>, whose entries <cite>A[m][i, j, k, …]</cite> store
the probability of observation level <cite>i</cite> given hidden state levels <cite>j, k, …</cite></p></li>
<li><p><strong>obs</strong> (<em>numpy 1D array</em><em>, </em><em>numpy ndarray of dtype object</em><em>, </em><em>int</em><em> or </em><em>tuple</em>) – The observation (generated by the environment). If single modality, this can be a 1D <cite>np.ndarray</cite>
(one-hot vector representation) or an <cite>int</cite> (observation index)
If multi-modality, this can be <cite>np.ndarray</cite> of dtype object whose entries are 1D one-hot vectors,
or a tuple (of <a href="#id1"><span class="problematic" id="id2">`</span></a>int`s)</p></li>
<li><p><strong>prior</strong> (<em>numpy 1D array</em><em>, </em><em>numpy ndarray of dtype object</em><em>, </em><em>optional</em>) – Prior beliefs about hidden states, to be integrated with the marginal likelihood to obtain
a posterior distribution. If not prvided, prior is set to be equal to a flat categorical distribution (at the level of
the individual inference functions).</p></li>
<li><p><strong>**kwargs</strong> (<em>keyword arguments</em>) – List of keyword/parameter arguments corresponding to parameter values for the fixed-point iteration
algorithm <cite>run_fpi.py</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>qs</strong> – Marginal posterior beliefs over hidden states</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy 1D array, numpy ndarray of dtype object, optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymdp.inference.update_posterior_states_v2">
<span class="sig-prename descclassname"><span class="pre">pymdp.inference.</span></span><span class="sig-name descname"><span class="pre">update_posterior_states_v2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prev_obs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policies</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prev_actions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_sep_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymdp.inference.update_posterior_states_v2" title="Permalink to this definition">¶</a></dt>
<dd><p>Update posterior over hidden states using marginal message passing</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>A</strong> (<em>numpy ndarray of dtype object</em>) – Sensory likelihood mapping or ‘observation model’, mapping from hidden states to observations. Each element <cite>A[m]</cite> of
stores an <cite>np.ndarray</cite> multidimensional array for observation modality <cite>m</cite>, whose entries <cite>A[m][i, j, k, …]</cite> store
the probability of observation level <cite>i</cite> given hidden state levels <cite>j, k, …</cite></p></li>
<li><p><strong>B</strong> (<em>numpy ndarray of dtype object</em>) – Dynamics likelihood mapping or ‘transition model’, mapping from hidden states at <cite>t</cite> to hidden states at <cite>t+1</cite>, given some control state <cite>u</cite>.
Each element B[f] of this object array stores a 3-D tensor for hidden state factor <cite>f</cite>, whose entries <cite>B[f][s, v, u] store the probability
of hidden state level `s</cite> at the current time, given hidden state level <cite>v</cite> and action <cite>u</cite> at the previous time.</p></li>
<li><p><strong>prev_obs</strong> (<em>list</em>) – List of observations over time. Each observation in the list can be an <cite>int</cite>, a <cite>list</cite> of ints, a <cite>tuple</cite> of ints, a one-hot vector or an object array of one-hot vectors.</p></li>
<li><p><strong>prior</strong> (<em>numpy ndarray of dtype object</em><em>, </em><em>optional</em>) – If provided, this a <cite>numpy</cite> object array with one sub-array per hidden state factor, that stores the prior beliefs about initial states.
If <cite>None</cite>, this defaults to a flat (uninformative) prior over hidden states.</p></li>
<li><p><strong>policy_sep_prior</strong> (<em>Bool</em><em>, </em><em>default True</em>) – -Flag determining whether the prior beliefs from the past are unconditioned on policy, or separated by /conditioned on the policy variable.</p></li>
<li><p><strong>**kwargs</strong> (<em>keyword arguments</em>) – Optional keyword arguments for the function <cite>run_mmp</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>qs_seq_pi</strong> – Posterior beliefs over hidden states for each policy. Nesting structure is policies, timepoints, factors,
where e.g. <cite>qs_seq_pi[p][t][f]</cite> stores the marginal belief about factor <cite>f</cite> at timepoint <cite>t</cite> under policy <cite>p</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy ndarray of dtype object</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymdp.inference.update_posterior_states_v2_test">
<span class="sig-prename descclassname"><span class="pre">pymdp.inference.</span></span><span class="sig-name descname"><span class="pre">update_posterior_states_v2_test</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prev_obs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policies</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prev_actions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_sep_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymdp.inference.update_posterior_states_v2_test" title="Permalink to this definition">¶</a></dt>
<dd><p>Update posterior over hidden states using marginal message passing
:param A: Sensory likelihood mapping or ‘observation model’, mapping from hidden states to observations. Each element <cite>A[m]</cite> of</p>
<blockquote>
<div><p>stores an <cite>np.ndarray</cite> multidimensional array for observation modality <cite>m</cite>, whose entries <cite>A[m][i, j, k, …]</cite> store
the probability of observation level <cite>i</cite> given hidden state levels <cite>j, k, …</cite></p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>B</strong> (<em>numpy ndarray of dtype object</em>) – Dynamics likelihood mapping or ‘transition model’, mapping from hidden states at <cite>t</cite> to hidden states at <cite>t+1</cite>, given some control state <cite>u</cite>.
Each element B[f] of this object array stores a 3-D tensor for hidden state factor <cite>f</cite>, whose entries <cite>B[f][s, v, u] store the probability
of hidden state level `s</cite> at the current time, given hidden state level <cite>v</cite> and action <cite>u</cite> at the previous time.</p></li>
<li><p><strong>prev_obs</strong> (<em>list</em>) – List of observations over time. Each observation in the list can be an <cite>int</cite>, a <cite>list</cite> of ints, a <cite>tuple</cite> of ints, a one-hot vector or an object array of one-hot vectors.</p></li>
<li><p><strong>prior</strong> (<em>numpy ndarray of dtype object</em><em>, </em><em>optional</em>) – If provided, this a <cite>numpy</cite> object array with one sub-array per hidden state factor, that stores the prior beliefs about initial states.
If <cite>None</cite>, this defaults to a flat (uninformative) prior over hidden states.</p></li>
<li><p><strong>policy_sep_prior</strong> (<em>Bool</em><em>, </em><em>default True</em>) – -Flag determining whether the prior beliefs from the past are unconditioned on policy, or separated by /conditioned on the policy variable.</p></li>
<li><p><strong>**kwargs</strong> (<em>keyword arguments</em>) – Optional keyword arguments for the function <cite>run_mmp</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>qs_seq_pi</strong> (<em>numpy ndarray of dtype object</em>) – Posterior beliefs over hidden states for each policy. Nesting structure is policies, timepoints, factors,
where e.g. <cite>qs_seq_pi[p][t][f]</cite> stores the marginal belief about factor <cite>f</cite> at timepoint <cite>t</cite> under policy <cite>p</cite>.</p></li>
<li><p><strong>F</strong> (<em>1D numpy ndarray</em>) – Vector of variational free energies for each policy</p></li>
<li><p><strong>xn_seq_pi</strong> (<em>numpy ndarray of of dtype object</em>) – Posterior beliefs over hidden states for each policy, for each iteration of marginal message passing.
Nesting structure is policy, iteration, factor, so xn_seq_p[p][itr][f] stores the <cite>num_states x infer_len</cite>
array of beliefs about hidden states at different time points of inference horizon.</p></li>
<li><p><strong>vn_seq_pi</strong> (<em>numpy ndarray of of dtype object</em>) – Prediction errors over hidden states for each policy, for each iteration of marginal message passing.
Nesting structure is policy, iteration, factor, so vn_seq_p[p][itr][f] stores the <cite>num_states x infer_len</cite>
array of beliefs about hidden states at different time points of inference horizon.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</section>
<span class="target" id="module-pymdp.control"></span><section id="control-py">
<h2>control.py<a class="headerlink" href="#control-py" title="Permalink to this headline">¶</a></h2>
<p>Functions for performing inference of policies (control states) in POMDP generative models,
according to the expected free energy</p>
<dl class="py function">
<dt class="sig sig-object py" id="pymdp.control.calc_expected_utility">
<span class="sig-prename descclassname"><span class="pre">pymdp.control.</span></span><span class="sig-name descname"><span class="pre">calc_expected_utility</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">qo_pi</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymdp.control.calc_expected_utility" title="Permalink to this definition">¶</a></dt>
<dd><p>Given expected observations under a policy Qo_pi and a prior over observations C
compute the expected utility of the policy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>multi-modality</strong><strong>)</strong><strong>]</strong> (<em>C</em><em> [</em><em>numpy object array</em><em> (</em><em>both single and</em>) – Expected observations under the given policy (predictive posterior over outcomes), for each timestep of planning
Each entry is the expected observations at a given timestep of the forward horizon.</p></li>
<li><p><strong>multi-modality</strong><strong>)</strong><strong>]</strong> – Prior beliefs over outcomes (e.g. preferences), encoded in terms of relative log probabilities. This is softmaxed to form
a proper probability distribution before being used to compute the expected utility.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Utility (reward) expected under the policy in question</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>expected_util [scalar]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymdp.control.calc_pA_info_gain">
<span class="sig-prename descclassname"><span class="pre">pymdp.control.</span></span><span class="sig-name descname"><span class="pre">calc_pA_info_gain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pA</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qo_pi</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qs_pi</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymdp.control.calc_pA_info_gain" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute expected Dirichlet information gain about parameters pA under a policy
:param pA [numpy object array]: Prior dirichlet parameters parameterizing beliefs about the likelihood</p>
<blockquote>
<div><p>mapping from hidden states to observations, with each modality-specific Dirichlet prior stored in different arrays.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>arrays</strong><strong>]</strong> (<em>qs_pi list of numpy object</em>) – Expected observations. Each element of the list is the posterior
predictive density over observations for a given timepoint of an expected trajectory</p></li>
<li><p><strong>arrays</strong><strong>]</strong> – Posterior predictive density over hidden states. Each element of the list
is the posterior predictive for a given timepoint of an expected trajectory</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Surprise (about dirichlet parameters) expected under the policy in question</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>infogain_pA [scalar]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymdp.control.calc_pB_info_gain">
<span class="sig-prename descclassname"><span class="pre">pymdp.control.</span></span><span class="sig-name descname"><span class="pre">calc_pB_info_gain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pB</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qs_pi</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qs_prev</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymdp.control.calc_pB_info_gain" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute expected Dirichlet information gain about parameters pB under a given policy
:param pB [numpy object array]: Prior dirichlet parameters parameterizing beliefs about the likelihood</p>
<blockquote>
<div><p>describing transitions between hidden states, with each factor-specific Dirichlet prior stored in different arrays.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>arrays</strong><strong>]</strong> (<em>qs_pi</em><em> [</em><em>list numpy object</em>) – Posterior predictive density over hidden states. Each element of the list
is the posterior predictive for a given timepoint of an expected trajectory.</p></li>
<li><p><strong>array</strong><strong>]</strong> (<em>qs_prev</em><em> [</em><em>numpy object</em>) – Posterior over hidden states (before getting observations)</p></li>
<li><p><strong>ndarray</strong> (<em>policy</em><em> [</em><em>numpy 2D</em>) – Policy to consider. Each row of the matrix encodes the action index
along a different control factor for a given timestep.</p></li>
<li><p><strong>n_control_factors</strong><strong>]</strong> (<em>of size n_steps x</em>) – Policy to consider. Each row of the matrix encodes the action index
along a different control factor for a given timestep.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Surprise (about dirichlet parameters) expected under the policy in question</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>infogain_pB [scalar]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymdp.control.calc_states_info_gain">
<span class="sig-prename descclassname"><span class="pre">pymdp.control.</span></span><span class="sig-name descname"><span class="pre">calc_states_info_gain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qs_pi</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymdp.control.calc_states_info_gain" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a likelihood mapping A and a posterior predictive density over states Qs_pi,
compute the Bayesian surprise (about states) expected under that policy
:param A [numpy object array (both single and multi-modality)]: Observation likelihood mapping from hidden states to observations, with</p>
<blockquote>
<div><p>different modalities (if there are multiple) stored in different sub-arrays of the object array.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>multi-factor</strong><strong>)</strong><strong>]</strong> (<em>qs_pi</em><em> [</em><em>list of</em><em> [</em><em>numpy object array</em><em> (</em><em>both single and</em>) – Posterior predictive density over hidden states. Each entry of
the list is the posterior predictive density over hidden states for a given timepoint
of an expected trajectory.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Bayesian surprise (about states) or salience expected under the policy in question</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>states_surprise [scalar]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymdp.control.construct_policies">
<span class="sig-prename descclassname"><span class="pre">pymdp.control.</span></span><span class="sig-name descname"><span class="pre">construct_policies</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_states</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_controls</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_len</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">control_fac_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymdp.control.construct_policies" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a set of policies</p>
<blockquote>
<div><p>Each policy is encoded as a numpy.ndarray of shape (n_steps, n_factors), where each
value corresponds to the index of an action for a given time step and control factor. The variable
<cite>policies</cite> that is returned is a list of each policy-specific numpy nd.array.</p>
</div></blockquote>
<dl>
<dt>.</dt><dd><ul class="simple">
<li><p><cite>num_states</cite>: list of dimensionalities of hidden state factors</p></li>
<li><p><cite>num_controls</cite>: list of dimensionalities of control state factors. If <cite>None</cite>, then defaults to being the dimensionality of each hidden state factor that is controllable</p></li>
<li><p><cite>policy_len</cite>: temporal length (‘horizon’) of policies</p></li>
<li><p><cite>control_fac_idx</cite>: list of indices of the hidden state factors</p></li>
</ul>
<p>that are controllable (i.e. those whose n_control[i] &gt; 1)</p>
<ul>
<li><dl>
<dt><cite>policies</cite>: list of np.ndarrays, where each array within the list is a</dt><dd><blockquote>
<div><p>numpy.ndarray of shape (n_steps, n_factors).</p>
</div></blockquote>
<p>Each value in a policy array corresponds to the index of an action for
a given timestep and control factor.</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymdp.control.get_expected_obs">
<span class="sig-prename descclassname"><span class="pre">pymdp.control.</span></span><span class="sig-name descname"><span class="pre">get_expected_obs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">qs_pi</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">A</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymdp.control.get_expected_obs" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a posterior predictive density Qs_pi and an observation likelihood model A,
get the expected observations given the predictive posterior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>array</strong><strong>)</strong> (<em>qs_pi</em><em> [</em><em>numpy object array</em><em> (</em><em>where each entry is a numpy 1D</em>) – Posterior predictive density over hidden states. If a list, each entry of the list is the
posterior predictive for a given timepoint of an expected trajectory</p></li>
<li><p><strong>arrays</strong><strong>]</strong> (<em>or list of numpy object</em>) – Posterior predictive density over hidden states. If a list, each entry of the list is the
posterior predictive for a given timepoint of an expected trajectory</p></li>
<li><p><strong>nd-array</strong> (<em>A</em><em> [</em><em>numpy</em>) – Observation likelihood mapping from hidden states to observations, with different modalities
(if there are multiple) stored in different arrays</p></li>
<li><p><strong>nd-array</strong><strong>)</strong><strong>]</strong> (<em>array-of-arrays</em><em> (</em><em>where each entry is a numpy</em>) – Observation likelihood mapping from hidden states to observations, with different modalities
(if there are multiple) stored in different arrays</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Expected observations under the given policy. If a list, a list of the expected observations
over the time horizon of policy evaluation, where each entry is the expected observations at a given timestep.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>qo_pi [numpy 1D array, array-of-arrays (where each entry is a numpy 1D array), or list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymdp.control.get_expected_states">
<span class="sig-prename descclassname"><span class="pre">pymdp.control.</span></span><span class="sig-name descname"><span class="pre">get_expected_states</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">qs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymdp.control.get_expected_states" title="Permalink to this definition">¶</a></dt>
<dd><blockquote>
<div><p>Given a posterior density qs, a transition likelihood model B, and a policy,
get the state distribution expected under that policy’s pursuit</p>
<ul class="simple">
<li><dl class="simple">
<dt><cite>qs</cite> [numpy 1D array, array-of-arrays (where each entry is a numpy 1D array)]:</dt><dd><p>Current posterior beliefs about hidden states</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><cite>B</cite> [numpy nd-array, array-of-arrays (where each entry is a numpy nd-array)]:</dt><dd><p>Transition likelihood mapping from states at t to states at t + 1, with different actions
(per factor) stored along the lagging dimension</p>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
<ul class="simple">
<li><dl class="simple">
<dt><cite>policy</cite> [np.arrays]:</dt><dd><p>np.array of size (policy_len x n_factors) where each value corrresponds to a control state</p>
</dd>
</dl>
</li>
</ul>
<blockquote>
<div><ul class="simple">
<li><dl class="simple">
<dt><cite>qs_pi</cite> [ list of numpy object arrays where <cite>len(qs_pi) == n_steps</cite>]</dt><dd><p>Expected states under the given policy - also referred to in the literature as the ‘posterior predictive density’</p>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymdp.control.get_num_controls_from_policies">
<span class="sig-prename descclassname"><span class="pre">pymdp.control.</span></span><span class="sig-name descname"><span class="pre">get_num_controls_from_policies</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">policies</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymdp.control.get_num_controls_from_policies" title="Permalink to this definition">¶</a></dt>
<dd><p>This calculates the list of dimensionalities of control factors
from the policy array.
&#64;NOTE:
This assumes a policy space such that for each control factor, there is at least
one policy that entails taking the action with the maximum index along that control factor.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymdp.control.sample_action">
<span class="sig-prename descclassname"><span class="pre">pymdp.control.</span></span><span class="sig-name descname"><span class="pre">sample_action</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">q_pi</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policies</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_controls</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_selection</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'deterministic'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymdp.control.sample_action" title="Permalink to this definition">¶</a></dt>
<dd><p>Samples action from posterior over policies, using one of two methods.
:param q_pi [1D numpy.ndarray]: Posterior beliefs about (possibly multi-step) policies.
:param policies [list of numpy ndarrays]: List of arrays that indicate the policies under consideration. Each element</p>
<blockquote>
<div><p>within the list is a matrix that stores the
the indices of the actions  upon the separate hidden state factors, at
each timestep (n_step x n_control_factor)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>integers</strong><strong>]</strong> (<em>num_controls</em><em> [</em><em>list of</em>) – List of the dimensionalities of the different (controllable)) hidden state factors</p></li>
<li><p><strong>[</strong><strong>string</strong> (<em>action_selection</em>) – Indicates whether the sampled action for a given hidden state factor is given by
the evidence for that action, marginalized across different policies (‘marginal_action’)
or simply the action entailed by a sample from the posterior over policies</p></li>
<li><p><strong>stochastic</strong><strong>]</strong> (<em>deterministic or</em>) – Indicates whether the sampled action for a given hidden state factor is given by
the evidence for that action, marginalized across different policies (‘marginal_action’)
or simply the action entailed by a sample from the posterior over policies</p></li>
<li><p><strong>[</strong><strong>np.float64</strong><strong>]</strong> (<em>alpha</em>) – Action selection precision – the inverse temperature of the softmax that is used to scale the
action marginals before sampling.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Numpy array containing the indices of the actions along each control factor</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>selected_policy [1D numpy ndarray]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymdp.control.update_posterior_policies">
<span class="sig-prename descclassname"><span class="pre">pymdp.control.</span></span><span class="sig-name descname"><span class="pre">update_posterior_policies</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">qs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policies</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_utility</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_states_info_gain</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_param_info_gain</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pA</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pB</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">E</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymdp.control.update_posterior_policies" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates the posterior beliefs about policies based on expected free energy prior</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>array</strong><strong>]</strong> (<em>- qs</em><em> [</em><em>numpy object</em>) – Current marginal beliefs about (single or multiple) hidden state factors</p></li>
<li><p><strong>multi-modality</strong><strong>)</strong><strong>]</strong> (<em>- C</em><em> [</em><em>numpy object array</em><em> (</em><em>both single and</em>) – Observation likelihood model</p></li>
<li><p><strong>multi-factor</strong><strong>)</strong><strong>]</strong> (<em>- B</em><em> [</em><em>numpy object array</em><em> (</em><em>both single and</em>) – Transition likelihood model</p></li>
<li><p><strong>multi-modality</strong><strong>)</strong><strong>]</strong> – Prior beliefs about outcomes (prior preferences)</p></li>
<li><p><strong>tuples</strong><strong>]</strong> (<em>- policies</em><em> [</em><em>list of</em>) – A list of all the possible policies, each expressed as a tuple of indices, where a given
index corresponds to an action on a particular hidden state factor e.g. policies[1][2] yields the
index of the action under policy 1 that affects hidden state factor 2</p></li>
<li><p><strong>[</strong><strong>bool</strong><strong>]</strong> (<em>- use_param_info_gain</em>) – Whether to calculate utility term, i.e how much expected observation confer with prior expectations</p></li>
<li><p><strong>[</strong><strong>bool</strong><strong>]</strong> – Whether to calculate state information gain</p></li>
<li><p><strong>[</strong><strong>bool</strong><strong>]</strong> – Whether to calculate parameter information gain &#64;NOTE requires pA or pB to be specified</p></li>
<li><p><strong>ndarray</strong> (<em>- pB</em><em> [</em><em>numpy</em>) – (both single and multi-modality)]:
Prior dirichlet parameters for A. Defaults to none, in which case info gain w.r.t. Dirichlet
parameters over A is skipped.</p></li>
<li><p><strong>modalities</strong><strong>)</strong> (<em>array-of-arrays</em><em> (</em><em>in case of multiple</em>) – (both single and multi-modality)]:
Prior dirichlet parameters for A. Defaults to none, in which case info gain w.r.t. Dirichlet
parameters over A is skipped.</p></li>
<li><p><strong>Dirichlet</strong> (<em>or</em>) – (both single and multi-modality)]:
Prior dirichlet parameters for A. Defaults to none, in which case info gain w.r.t. Dirichlet
parameters over A is skipped.</p></li>
<li><p><strong>ndarray</strong> – Dirichlet (both single and multi-factor)]:
Prior dirichlet parameters for B. Defaults to none, in which case info gain w.r.t.
Dirichlet parameters over A is skipped.</p></li>
<li><p><strong>factors</strong><strong>)</strong> (<em>array-of-arrays</em><em> (</em><em>in case of multiple hidden state</em>) – Dirichlet (both single and multi-factor)]:
Prior dirichlet parameters for B. Defaults to none, in which case info gain w.r.t.
Dirichlet parameters over A is skipped.</p></li>
<li><p><strong>or</strong> – Dirichlet (both single and multi-factor)]:
Prior dirichlet parameters for B. Defaults to none, in which case info gain w.r.t.
Dirichlet parameters over A is skipped.</p></li>
<li><p><strong>E</strong> (<em>-</em>) – </p></li>
<li><p><strong>[</strong><strong>float</strong> (<em>- gamma</em>) – Precision over policies, used as the inverse temperature parameter of a softmax transformation
of the expected free energies of each policy</p></li>
<li><p><strong>16.0</strong><strong>]</strong> (<em>defaults to</em>) – Precision over policies, used as the inverse temperature parameter of a softmax transformation
of the expected free energies of each policy</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul>
<li><ul class="simple">
<li><p><cite>qp</cite> [1D numpy array] – Posterior beliefs about policies, defined here as a softmax function of the</p></li>
</ul>
<p>(gamma-weighted) expected free energies of policies</p>
</li>
<li><ul class="simple">
<li><p><cite>efe</cite> - [1D numpy array] – A vector containing the expected free energies of each policy</p></li>
</ul>
</li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymdp.control.update_posterior_policies_mmp">
<span class="sig-prename descclassname"><span class="pre">pymdp.control.</span></span><span class="sig-name descname"><span class="pre">update_posterior_policies_mmp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">qs_seq_pi</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policies</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_utility</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_states_info_gain</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_param_info_gain</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pA</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pB</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">F</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">E</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymdp.control.update_posterior_policies_mmp" title="Permalink to this definition">¶</a></dt>
<dd><p>Update posterior beliefs about policies by computing expected free energy of each policy and integrating that
with the variational free energy of policies <cite>F</cite> and prior over policies <cite>E</cite>.
qs_seq_pi: numpy ndarray of dtype object</p>
<blockquote>
<div><p>Posterior beliefs over hidden states for each policy. Nesting structure is policies, timepoints, factors,
where e.g. <cite>qs_seq_pi[p][t][f]</cite> stores the marginal belief about factor <cite>f</cite> at timepoint <cite>t</cite> under policy <cite>p</cite>.</p>
</div></blockquote>
<dl class="simple">
<dt>A: numpy ndarray of dtype object</dt><dd><p>Sensory likelihood mapping or ‘observation model’, mapping from hidden states to observations. Each element <cite>A[m]</cite> of
stores an <cite>np.ndarray</cite> multidimensional array for observation modality <cite>m</cite>, whose entries <cite>A[m][i, j, k, …]</cite> store
the probability of observation level <cite>i</cite> given hidden state levels <cite>j, k, …</cite></p>
</dd>
<dt>B: numpy ndarray of dtype object</dt><dd><p>Dynamics likelihood mapping or ‘transition model’, mapping from hidden states at <cite>t</cite> to hidden states at <cite>t+1</cite>, given some control state <cite>u</cite>.
Each element B[f] of this object array stores a 3-D tensor for hidden state factor <cite>f</cite>, whose entries <cite>B[f][s, v, u] store the probability
of hidden state level `s</cite> at the current time, given hidden state level <cite>v</cite> and action <cite>u</cite> at the previous time.</p>
</dd>
<dt>policies: numpy ndarray of dtype object</dt><dd><p>Array that stores each policy in <cite>policies[p_idx]</cite>. Shape of <cite>policies[p_idx]</cite> is <cite>(num_timesteps, num_factors)</cite> where <cite>num_factors</cite> is the
number of control factors.</p>
</dd>
<dt>use_utility: Bool, default True</dt><dd><p>Boolean flag that determines whether expected utility should be incorporated into computation of EFE</p>
</dd>
<dt>use_states_info_gain: Bool, default True</dt><dd><p>Boolean flag that determines whether state epistemic value (info gain about hidden states) should be incorporated into computation of EFE</p>
</dd>
<dt>use_param_info_gain: Bool, default False</dt><dd><p>Boolean flag that determines whether parameter epistemic value (info gain about generative model parameters) should be incorporated into computation of EFE</p>
</dd>
<dt>prior: numpy ndarray of dtype object, optional</dt><dd><p>If provided, this a <cite>numpy</cite> object array with one sub-array per hidden state factor, that stores the prior beliefs about initial states.
If <cite>None</cite>, this defaults to a flat (uninformative) prior over hidden states.</p>
</dd>
<dt>pA: numpy ndarray of dtype object, optional</dt><dd><p>Dirichlet parameters over observation model (same shape as A)</p>
</dd>
<dt>pB: numpy ndarray of dtype object, optional</dt><dd><p>Dirichlet parameters over transition model (same shape as B)</p>
</dd>
<dt>F: 1D numpy ndarray, optional</dt><dd><p>Vector of variational free energies for each policy</p>
</dd>
<dt>E: 1D numpy ndarray, optional</dt><dd><p>Vector of prior probabilities of each policy (what’s referred to in the active inference literature as “habits”)</p>
</dd>
<dt>gamma: float, default 16.0</dt><dd><p>Prior precision over policies, scales the contribution of the expected free energy to the posterior over policies</p>
</dd>
</dl>
</dd></dl>

</section>
<span class="target" id="module-pymdp.learning"></span><section id="learning-py">
<h2>learning.py<a class="headerlink" href="#learning-py" title="Permalink to this headline">¶</a></h2>
<p>Functions updating parameters of Dirichlet distributions in POMDP generative models</p>
<dl class="py function">
<dt class="sig sig-object py" id="pymdp.learning.prune_A">
<span class="sig-prename descclassname"><span class="pre">pymdp.learning.</span></span><span class="sig-name descname"><span class="pre">prune_A</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs_levels_to_prune</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state_levels_to_prune</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dirichlet</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymdp.learning.prune_A" title="Permalink to this definition">¶</a></dt>
<dd><p>Function for pruning a observation likelihood (with potentially multiple hidden state factors)
Arguments:
=========
<cite>A</cite> [np.ndarray or numpy object array]: The observation model or mapping from hidden states to observations (A matrix) of the generative model.
<cite>obs_levels_to_prune</cite> [list]: a list of the observation levels to remove. If the likelihood in question has multiple observation modalities,</p>
<blockquote>
<div><p>then this will be a list of lists, where each sub-list within <cite>obs_levels_to_prune</cite> will contain the observation levels to prune for a particular observation modality</p>
</div></blockquote>
<p><cite>state_levels_to_prune</cite> [list]: a list of the hidden state levels to remove (this will be the same across modalities, so it won’t matter whether the <cite>likelihood</cite> array that’s
passed in is an object array or not)
<cite>dirichlet</cite> [bool]: a flag telling whether the input array is a Dirichlet and therefore should not be normalized at the end. &#64;TODO: Instead, the dirichlet parameters from the</p>
<blockquote>
<div><p>pruned columns should somehow be re-distributed among the remaining columns</p>
</div></blockquote>
<p><cite>reduced_A</cite> [np.ndarray or numpy object array]: The observation model, after pruning, which lacks the observation or hidden state levels given by the arguments <cite>obs_levels_to_prune</cite> and <cite>state_levels_to_prune</cite></p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymdp.learning.prune_B">
<span class="sig-prename descclassname"><span class="pre">pymdp.learning.</span></span><span class="sig-name descname"><span class="pre">prune_B</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state_levels_to_prune</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_levels_to_prune</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dirichlet</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymdp.learning.prune_B" title="Permalink to this definition">¶</a></dt>
<dd><p>Function for pruning a transition likelihood (with potentially multiple hidden state factors)
Arguments:
=========
<cite>B</cite> [np.ndarray or numpy object array]: The transition model or mapping from hidden states at time t to hidden states at time t+1 (B matrix) of the generative model.
<cite>state_levels_to_prune</cite> [list]: a list of the hidden state levels to remove, one per hidden state factor. Or just a list of integers if there’s one hidden state factor
<cite>action_levels_to_prune</cite> [list]: a list of the action levels to remove, one per control state factor. Or just a list of integers if there’s one control state factor
<cite>dirichlet</cite> [bool]: a flag telling whether the input array is a Dirichlet and therefore should not be normalized at the end. &#64;TODO: Instead, the dirichlet parameters from the</p>
<blockquote>
<div><p>pruned columns should somehow be re-distributed among the remaining columns</p>
</div></blockquote>
<p><cite>reduced_B</cite> [np.ndarray or numpy object array]: The transition model, after pruning, which lacks the hidden state levels /action levels given by the arguments <cite>state_levels_to_prune</cite> and <cite>action_levels_to_prune</cite></p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymdp.learning.prune_prior">
<span class="sig-prename descclassname"><span class="pre">pymdp.learning.</span></span><span class="sig-name descname"><span class="pre">prune_prior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prior</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">levels_to_remove</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymdp.learning.prune_prior" title="Permalink to this definition">¶</a></dt>
<dd><p>Function for pruning a prior (with potentially multiple hidden state factors)
Arguments:
=========
<cite>prior</cite> [1D np.ndarray or numpy object array with 1D entries]: The prior vector(s) containing the priors of a generative model, e.g. the prior over hidden states (D vector).
<cite>levels_to_remove</cite> [list]: a list of the hidden state or observation levels to remove. If the prior in question has multiple hidden state factors / multiple observation modalities,</p>
<blockquote>
<div><p>then this will be a list of lists, where each sub-list within <cite>levels_to_remove</cite> will contain the levels to prune for a particular hidden state factor or modality</p>
</div></blockquote>
<dl class="simple">
<dt><cite>dirichlet</cite> [bool]: a flag telling whether the input array is a Dirichlet and therefore should not be normalized at the end. &#64;TODO: Instead, the dirichlet parameters from the</dt><dd><p>pruned columns should somehow be re-distributed among the remaining columns</p>
</dd>
</dl>
<p><cite>reduced_prior</cite> [1D np.ndarray or numpy object array with 1D entries]: The prior vector(s), after pruning, lacks the hidden state or modality levels indexed by <cite>levels_to_remove</cite></p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymdp.learning.update_likelihood_dirichlet">
<span class="sig-prename descclassname"><span class="pre">pymdp.learning.</span></span><span class="sig-name descname"><span class="pre">update_likelihood_dirichlet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pA</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">modalities</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'all'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymdp.learning.update_likelihood_dirichlet" title="Permalink to this definition">¶</a></dt>
<dd><p>Update Dirichlet parameters of the likelihood distribution</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>array</strong><strong>]</strong> (<em>- A</em><em> [</em><em>numpy object</em>) – The prior Dirichlet parameters of the generative model, parameterizing the
agent’s beliefs about the observation likelihood.</p></li>
<li><p><strong>array</strong><strong>]</strong> – The observation likelihood of the generative model.</p></li>
<li><p><strong>array</strong> (<em>- obs</em><em> [</em><em>numpy 1D</em>) – A discrete observation (possible multi-modality) used in the update equation.
&#64;NOTE on input formats:
- If <cite>obs</cite> is a 1D numpy array, it must be a one-hot vector, where one entry (the entry of the observation) is 1.0
and all other entries are 0. This therefore assumes it’s a single modality observation.
- If <cite>obs</cite> is an int, it assumes this is a single modality observation, whose observation index is given by the value of <cite>obs</cite>
- If <cite>obs</cite> is a list, it assumes this is a multiple modality observation, whose len is equal to the number of observation modalities,
and where each entry <cite>obs[m]</cite> is the index of the observation, for that modality.
- If <cite>obs</cite> is a tuple, same logic as applies for list (see above).
- if <cite>obs</cite> is a numpy object array (array of arrays), then this assumes the observation is a multiple modality observation, where each
sub-array of <cite>obs</cite> is a 1D numpy array with a 1.0 in one entry and 0 everywhere else – i.e. an object array of onehots.</p></li>
<li><p><strong>entries</strong><strong>)</strong> (<em>array-of-arrays</em><em> (</em><em>with 1D numpy array</em>) – A discrete observation (possible multi-modality) used in the update equation.
&#64;NOTE on input formats:
- If <cite>obs</cite> is a 1D numpy array, it must be a one-hot vector, where one entry (the entry of the observation) is 1.0
and all other entries are 0. This therefore assumes it’s a single modality observation.
- If <cite>obs</cite> is an int, it assumes this is a single modality observation, whose observation index is given by the value of <cite>obs</cite>
- If <cite>obs</cite> is a list, it assumes this is a multiple modality observation, whose len is equal to the number of observation modalities,
and where each entry <cite>obs[m]</cite> is the index of the observation, for that modality.
- If <cite>obs</cite> is a tuple, same logic as applies for list (see above).
- if <cite>obs</cite> is a numpy object array (array of arrays), then this assumes the observation is a multiple modality observation, where each
sub-array of <cite>obs</cite> is a 1D numpy array with a 1.0 in one entry and 0 everywhere else – i.e. an object array of onehots.</p></li>
<li><p><strong>int</strong> – A discrete observation (possible multi-modality) used in the update equation.
&#64;NOTE on input formats:
- If <cite>obs</cite> is a 1D numpy array, it must be a one-hot vector, where one entry (the entry of the observation) is 1.0
and all other entries are 0. This therefore assumes it’s a single modality observation.
- If <cite>obs</cite> is an int, it assumes this is a single modality observation, whose observation index is given by the value of <cite>obs</cite>
- If <cite>obs</cite> is a list, it assumes this is a multiple modality observation, whose len is equal to the number of observation modalities,
and where each entry <cite>obs[m]</cite> is the index of the observation, for that modality.
- If <cite>obs</cite> is a tuple, same logic as applies for list (see above).
- if <cite>obs</cite> is a numpy object array (array of arrays), then this assumes the observation is a multiple modality observation, where each
sub-array of <cite>obs</cite> is a 1D numpy array with a 1.0 in one entry and 0 everywhere else – i.e. an object array of onehots.</p></li>
<li><p><strong>list</strong> – A discrete observation (possible multi-modality) used in the update equation.
&#64;NOTE on input formats:
- If <cite>obs</cite> is a 1D numpy array, it must be a one-hot vector, where one entry (the entry of the observation) is 1.0
and all other entries are 0. This therefore assumes it’s a single modality observation.
- If <cite>obs</cite> is an int, it assumes this is a single modality observation, whose observation index is given by the value of <cite>obs</cite>
- If <cite>obs</cite> is a list, it assumes this is a multiple modality observation, whose len is equal to the number of observation modalities,
and where each entry <cite>obs[m]</cite> is the index of the observation, for that modality.
- If <cite>obs</cite> is a tuple, same logic as applies for list (see above).
- if <cite>obs</cite> is a numpy object array (array of arrays), then this assumes the observation is a multiple modality observation, where each
sub-array of <cite>obs</cite> is a 1D numpy array with a 1.0 in one entry and 0 everywhere else – i.e. an object array of onehots.</p></li>
<li><p><strong>tuple</strong><strong>]</strong> (<em>or</em>) – A discrete observation (possible multi-modality) used in the update equation.
&#64;NOTE on input formats:
- If <cite>obs</cite> is a 1D numpy array, it must be a one-hot vector, where one entry (the entry of the observation) is 1.0
and all other entries are 0. This therefore assumes it’s a single modality observation.
- If <cite>obs</cite> is an int, it assumes this is a single modality observation, whose observation index is given by the value of <cite>obs</cite>
- If <cite>obs</cite> is a list, it assumes this is a multiple modality observation, whose len is equal to the number of observation modalities,
and where each entry <cite>obs[m]</cite> is the index of the observation, for that modality.
- If <cite>obs</cite> is a tuple, same logic as applies for list (see above).
- if <cite>obs</cite> is a numpy object array (array of arrays), then this assumes the observation is a multiple modality observation, where each
sub-array of <cite>obs</cite> is a 1D numpy array with a 1.0 in one entry and 0 everywhere else – i.e. an object array of onehots.</p></li>
<li><p><strong>array</strong><strong>)</strong><strong>]</strong> (<em>- qs</em><em> [</em><em>numpy object array</em><em> (</em><em>where each entry is a numpy 1D</em>) – Current marginal posterior beliefs about hidden state factors</p></li>
<li><p><strong>[</strong><strong>float</strong> (<em>- lr</em>) – Learning rate.</p></li>
<li><p><strong>optional</strong><strong>]</strong> – Learning rate.</p></li>
<li><p><strong>[</strong><strong>list</strong> (<em>- modalities</em>) – Indices (in terms of range(n_modalities)) of the observation modalities to include
in learning.Defaults to ‘all’, meaning that observation likelihood matrices
for all modalities are updated using their respective observations.</p></li>
<li><p><strong>optional</strong><strong>]</strong> – Indices (in terms of range(n_modalities)) of the observation modalities to include
in learning.Defaults to ‘all’, meaning that observation likelihood matrices
for all modalities are updated using their respective observations.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymdp.learning.update_state_prior_dirichlet">
<span class="sig-prename descclassname"><span class="pre">pymdp.learning.</span></span><span class="sig-name descname"><span class="pre">update_state_prior_dirichlet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pD</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">factors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'all'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymdp.learning.update_state_prior_dirichlet" title="Permalink to this definition">¶</a></dt>
<dd><blockquote>
<div><p>Update Dirichlet parameters that parameterize the hidden state prior of the generative model
(prior beliefs about hidden states at the beginning of the inference window).</p>
</div></blockquote>
<ul class="simple">
<li><dl class="simple">
<dt>pD [numpy object array]:</dt><dd><p>The prior Dirichlet parameters of the generative model, parameterizing the agent’s
beliefs about initial hidden states</p>
</dd>
</dl>
</li>
</ul>
<blockquote>
<div><ul class="simple">
<li><dl class="simple">
<dt>qs [numpy object array (where each entry is a numpy 1D array)]:</dt><dd><p>Current marginal posterior beliefs about hidden state factors</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>lr [float, optional]:</dt><dd><p>Learning rate.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>factors [list, optional]:</dt><dd><p>Indices (in terms of range(num_factors)) of the hidden state factors to include in learning.
Defaults to ‘all’, meaning that the priors over initial hidden states for all hidden state factors
are updated.</p>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymdp.learning.update_transition_dirichlet">
<span class="sig-prename descclassname"><span class="pre">pymdp.learning.</span></span><span class="sig-name descname"><span class="pre">update_transition_dirichlet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pB</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qs_prev</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">factors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'all'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymdp.learning.update_transition_dirichlet" title="Permalink to this definition">¶</a></dt>
<dd><blockquote>
<div><p>Update Dirichlet parameters that parameterize the transition model of the generative model
(describing the probabilistic mapping between hidden states over time).</p>
</div></blockquote>
<ul class="simple">
<li><dl class="simple">
<dt>pB [numpy object array]:</dt><dd><p>The prior Dirichlet parameters of the generative model, parameterizing the agent’s
beliefs about the transition likelihood.</p>
</dd>
</dl>
</li>
</ul>
<blockquote>
<div><ul class="simple">
<li><dl class="simple">
<dt>B [numpy object array]:</dt><dd><p>The transition likelihood of the generative model.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>actions [numpy 1D array]:</dt><dd><p>A 1D numpy array of shape (num_control_factors,) containing the action(s) performed at
a given timestep.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>qs [numpy object array (where each entry is a numpy 1D array)]:</dt><dd><p>Current marginal posterior beliefs about hidden state factors</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>qs_prev [numpy object array (where each entry is a numpy 1D array)]:</dt><dd><p>Past marginal posterior beliefs about hidden state factors</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>lr [float, optional]:</dt><dd><p>Learning rate.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>factors [list, optional]:</dt><dd><p>Indices (in terms of range(num_factors)) of the hidden state factors to include in learning.
Defaults to ‘all’, meaning that transition likelihood matrices for all hidden state factors
are updated as a function of transitions in the different control factors (i.e. actions)</p>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
</dd></dl>

</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Modules</a><ul>
<li><a class="reference internal" href="#inference-py">inference.py</a></li>
<li><a class="reference internal" href="#control-py">control.py</a></li>
<li><a class="reference internal" href="#learning-py">learning.py</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="index.html"
                        title="previous chapter">Welcome to pymdp’s documentation!</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/modules.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="index.html" title="Welcome to pymdp’s documentation!"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">pymdp 0.0.3 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Modules</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2021, infer-actively.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.2.0.
    </div>
  </body>
</html>