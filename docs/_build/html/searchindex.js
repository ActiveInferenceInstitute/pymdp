Search.setIndex({docnames:["generated/pymdp","index","modules","usage"],envversion:{"sphinx.domains.c":2,"sphinx.domains.changeset":1,"sphinx.domains.citation":1,"sphinx.domains.cpp":4,"sphinx.domains.index":1,"sphinx.domains.javascript":2,"sphinx.domains.math":2,"sphinx.domains.python":3,"sphinx.domains.rst":2,"sphinx.domains.std":2,sphinx:56},filenames:["generated/pymdp.rst","index.rst","modules.rst","usage.rst"],objects:{"":{pymdp:[0,0,0,"-"]},"pymdp.control":{calc_expected_utility:[2,1,1,""],calc_pA_info_gain:[2,1,1,""],calc_pB_info_gain:[2,1,1,""],calc_states_info_gain:[2,1,1,""],construct_policies:[2,1,1,""],get_expected_obs:[2,1,1,""],get_expected_states:[2,1,1,""],get_num_controls_from_policies:[2,1,1,""],sample_action:[2,1,1,""],update_posterior_policies:[2,1,1,""],update_posterior_policies_mmp:[2,1,1,""]},"pymdp.inference":{average_states_over_policies:[2,1,1,""],update_posterior_states:[2,1,1,""],update_posterior_states_v2:[2,1,1,""],update_posterior_states_v2_test:[2,1,1,""]},"pymdp.learning":{prune_A:[2,1,1,""],prune_B:[2,1,1,""],prune_prior:[2,1,1,""],update_likelihood_dirichlet:[2,1,1,""],update_state_prior_dirichlet:[2,1,1,""],update_transition_dirichlet:[2,1,1,""]},pymdp:{control:[2,0,0,"-"],inference:[2,0,0,"-"],learning:[2,0,0,"-"]}},objnames:{"0":["py","module","Python module"],"1":["py","function","Python function"]},objtypes:{"0":"py:module","1":"py:function"},terms:{"0":2,"1":2,"10":2,"10708":2,"13":2,"137":2,"16":2,"18":2,"1d":2,"2":2,"221":2,"24":2,"2d":2,"3":2,"38":2,"boolean":2,"case":2,"class":[1,2],"default":2,"float":2,"function":2,"int":2,"return":2,"true":2,A:2,If:2,Or:2,The:[1,2],To:3,__author__:[],about:2,abov:2,accord:2,across:2,action:2,action_levels_to_prun:2,action_select:2,activ:[1,2],affect:2,after:2,agent:[1,2],alexand:[],algorithm:2,all:2,along:2,alpha:2,also:2,among:2,an:2,api:[],appli:2,ar:2,argument:2,arrai:2,assum:2,averag:2,average_states_over_polici:2,b:2,base:2,bayesian:2,befor:2,begin:2,being:2,belief:2,bespok:1,between:2,bool:2,both:2,brennan:[],c:2,calc_expected_util:2,calc_pa_info_gain:2,calc_pb_info_gain:2,calc_states_info_gain:2,calcul:2,can:2,categor:2,citeseerx:2,clarifi:[],cmu:2,column:2,comput:2,condit:2,confer:2,conor:[],consid:2,consider:2,construct_polici:2,contain:2,contribut:2,control:1,control_fac_idx:2,correspond:2,corrrespond:2,cs:2,current:2,d:2,data:[],decis:1,defin:2,densiti:2,describ:2,design:1,detail:2,determin:2,determinist:2,differ:2,dimens:2,dimension:2,dirichlet:2,discret:[1,2],distribut:2,doi:2,download:2,dtype:2,dynam:2,e:2,each:2,edu:2,ef:2,element:2,els:2,enabl:1,encod:2,end:2,energi:2,entail:2,entri:2,environ:2,epistem:2,equal:2,equat:2,error:2,evalu:2,everywher:2,evid:2,expect:2,expected_util:2,express:2,f:2,factor:2,fals:2,field:2,first:3,fix:2,flag:2,flat:2,flexibl:1,float64:2,follow:2,form:2,format:2,forward:2,fpi:2,free:2,from:2,g:2,gain:2,gamma:2,gener:[1,2],get:2,get_expected_ob:2,get_expected_st:2,get_num_controls_from_polici:2,given:[1,2],guestrin:2,ha:2,habit:2,hein:[],here:2,hidden:2,horizon:2,hot:2,how:2,http:2,i:2,includ:2,incorpor:2,index:[1,2],indic:2,individu:2,infer:1,infer_len:2,inferact:3,info:2,infogain_pa:2,infogain_pb:2,inform:2,initi:2,input:2,instal:[],instead:2,integ:2,integr:2,invers:2,invert:[],ist:2,iter:2,itr:2,j:2,just:2,k:2,keyword:2,klein:[],known:2,kwarg:2,lack:2,lag:2,learn:1,least:2,len:2,length:2,level:[1,2],levels_to_remov:2,likelihood:2,link:2,list:2,literatur:2,log:2,logic:2,lr:2,m:2,map:2,margin:2,marginal_act:2,markov:1,matric:2,matrix:2,matter:2,maximum:2,mean:2,messag:2,method:2,modal:2,model:[1,2],modul:1,modular:1,much:2,multi:2,multidimension:2,multifactori:[],multipl:2,must:2,n_control:2,n_control_factor:2,n_factor:2,n_modal:2,n_step:2,nd:2,ndarrai:2,nest:2,none:2,normal:2,note:2,np:2,num_control:2,num_control_factor:2,num_factor:2,num_polici:2,num_stat:2,num_timestep:2,number:2,numpi:2,numpyndarrai:[],ob:2,object:2,obs_levels_to_prun:2,observ:[1,2],obtain:2,one:2,onehot:2,ooption:[],option:2,other:2,outcom:2,over:2,p:2,p_idx:2,pa:2,packag:1,page:1,param:2,paramet:2,parameter:2,partial:1,particular:2,pass:2,past:2,pb:2,pd:2,pdf:2,per:2,perform:2,pip:3,plan:2,point:2,polici:2,policy_len:2,policy_sep_prior:2,pomdp:[1,2],possibl:2,posterior:2,potenti:2,precis:2,predict:2,prefer:2,prev_act:2,prev_ob:2,previou:2,prior:2,probabilist:2,probabl:2,process:1,proper:2,provid:2,prune:2,prune_a:2,prune_b:2,prune_prior:2,prvide:2,psu:2,pursuit:2,py:1,pymdp:[2,3],python:1,q_pi:2,qo_pi:2,qp:2,qs:2,qs_bma:2,qs_pi:2,qs_prev:2,qs_seq_pi:2,question:2,r9:2,r:2,rang:2,rate:2,re:2,recit:2,reduced_a:2,reduced_b:2,reduced_prior:2,refer:2,rel:2,remain:2,remov:2,rep1:2,rep:2,represent:2,requir:2,respect:2,reward:2,row:2,rst:2,run_fpi:2,run_mmp:2,s:2,salienc:2,same:2,sampl:2,sample_act:2,scalar:2,scale:2,search:1,see:2,select:2,selected_polici:2,sensori:2,separ:2,set:2,shape:2,should:2,simpli:2,simul:1,singl:2,size:2,skip:2,slide:2,so:2,softmax:2,some:2,somehow:2,space:[1,2],specif:[1,2],specifi:2,state:[1,2],state_levels_to_prun:2,states_surpris:2,step:2,stochast:2,store:2,string:2,structur:2,sub:2,surpris:2,t:2,take:2,task:1,tell:2,temperatur:2,tempor:2,tensor:2,term:2,therefor:2,thi:2,those:2,time:[1,2],timepoint:2,timestep:2,todo:2,trajectori:2,transform:2,transit:2,tschantz:[],tupl:2,two:2,type:2,u:2,uncondit:2,under:2,uninform:2,updat:2,update_likelihood_dirichlet:2,update_posterior_polici:2,update_posterior_policies_mmp:2,update_posterior_st:2,update_posterior_states_v2:2,update_posterior_states_v2_test:2,update_state_prior_dirichlet:2,update_transition_dirichlet:2,upon:2,us:[1,2,3],usag:[],use_param_info_gain:2,use_states_info_gain:2,use_util:2,user:1,util:2,v:2,valu:2,vari:1,variabl:2,variat:2,vector:2,venv:3,vi:2,view:2,viewdoc:2,vn_seq_p:2,vn_seq_pi:2,w:2,weight:2,what:2,when:[],where:2,whether:2,which:2,whose:2,window:2,within:2,won:2,www:2,x:2,xn_seq_p:2,xn_seq_pi:2,yield:2},titles:["pymdp","Welcome to pymdp\u2019s documentation!","Modules","Usage"],titleterms:{api:1,control:2,develop:1,document:1,indic:1,infer:2,instal:3,learn:2,modul:2,py:2,pymdp:[0,1],refer:1,s:1,tabl:1,usag:3,welcom:1}})